本周阅读**Database-System-Concepts-7th-Edition**:PART FOUR BIG DATA ANALYTICS,知识点总结如下：  
**Chapter 10 Big Data**(p467-516)    
>日期：4.22

### 大数据（Big Data）概述
- **数据规模增长**：20世纪90年代末和21世纪初，网络的快速发展促使数据量大幅增长。用户生成数据（如社交媒体数据）、交易网站数据（用户浏览和购买记录）等大量涌现，远超传统数据库系统处理能力。
- **与传统数据库对比**
    - **Volume（规模）**：大数据要存储和处理的数据量远超传统数据库，新应用需数千台机器并行处理数据，而早期并行数据库仅设计用于数十到数百台机器。
    - **Velocity（速度）**：在网络世界中，数据到达速率更高，数据管理系统需高速摄取和存储数据，许多应用要求实时处理数据（如流数据系统）。 
    - **Variety（多样性）**：传统关系型数据表示、查询语言和数据库系统虽成功，但大数据包含半结构化数据、文本数据、图形数据等多种格式，SQL在处理部分大数据计算时存在局限，新语言和框架应运而生。

### 大数据的来源和用途
- **来源**
    - **Web服务器日志**：记录用户与网站交互信息，早期数据来源，随着用户增多，大型网络公司每天产生数TB数据。
    - **移动应用数据**：类似于网站点击数据，帮助理解用户与应用交互情况。 
    - **零售企业交易数据**：包括线上线下，如沃尔玛等早期使用并行数据库管理分析数据。 
    - **传感器数据**：高端设备用于监测设备状态，物联网使设备联网，设备数量超互联网用户数。 
    - **通信网络元数据**：包含流量等监测信息，用于检测潜在问题、容量规划等。 
- **用途**
    - 决定向用户展示的内容，提升用户参与度。
    - 确定广告投放对象，提高广告相关性。 
    - 优化网站结构，便于用户查找信息。 
    - 分析用户偏好和趋势，辅助企业生产和库存决策。 
    - 衡量广告展示和点击效果（点击量、转化率），决定广告投放策略。 

### 查询大数据（Querying Big Data）
- **SQL局限性**：SQL是查询关系型数据库最广泛使用语言，但大数据应用需处理更多数据类型和更大规模/速度数据，因此有更多查询语言选择。
- **大数据应用分类**
    - **事务处理系统（Transaction - processing systems）**：需高可扩展性，支持大量短查询和更新。放松关系数据库特性要求，数据存储采用键值对存储（key - value store），如社交网络应用中处理用户帖子和好友信息，可通过应用代码或视图物化实现连接操作，不同实现方式存在查询成本和存储成本等方面的权衡。
    - **查询处理系统（Query processing systems）**：需高可扩展性，支持非关系型数据，如分析Web服务器日志、文档和知识存储索引系统（支持关键词搜索）。

### 大数据存储系统（Big Data Storage Systems）
- **高扩展性需求**：大数据应用对扩展性要求极高，许多热门应用拥有数亿用户，且负载在短时间内大幅增长，需将数据存储在数千个计算和存储节点上。
- **大数据存储系统类型**
    - **分布式文件系统（Distributed File Systems）**
        - **特点**：允许文件存储在多台机器上，通过传统文件系统接口访问，用于存储大文件（如日志文件），也可作为支持记录存储系统的存储层。 
        - **示例**：Google File System（GFS）是早期标志性系统，Hadoop File System（HDFS）基于GFS架构，应用广泛。 
        - **存储机制**：文件分割成多个块，分散存储在多台机器上，每个文件块通常在多台（一般为3台）机器上复制，防止机器故障导致文件不可访问。 
        - **功能支持**：具备目录系统，实现文件分层组织；支持文件名到存储实际数据块标识符序列的映射；能对指定标识符的块进行数据存储和检索。以HDFS为例，核心是运行NameNode的服务器，接收所有文件系统请求。客户端读文件时发送文件名，NameNode返回块标识符和存储机器标识符；写文件时，NameNode创建新块标识符并分配给机器，客户端将块标识符和数据发送到指定机器存储。可通过多种语言（如Java、Python）的HDFS文件系统API访问文件，也可将HDFS连接到本地文件系统，像访问本地文件一样访问HDFS文件。
    - **跨多个数据库分片（Sharding across multiple databases）**
        - **概念**：将记录划分到多个系统的过程，即把数据分散到多个数据库中。典型用例是按用户将记录划分到多个数据库，每个数据库是传统集中式数据库，客户端软件负责跟踪记录划分并将查询发送到合适数据库。 
        - **分区方式**：通常依据一个或多个属性（分区属性、分区键或分片键）进行分区，用户或账户标识符常用作分区键。分区方法有范围分区（如1 - 100,000的键分配给第一个数据库，100,001 - 200,000的键分配给第二个数据库等）和哈希分区（通过哈希函数将键值映射到分区号） 。 
        - **挑战**：应用代码实现分片时，需跟踪数据存储位置并路由查询；跨多个数据库的读或更新查询难以简单处理，需从多个数据库读取数据计算结果；数据库过载时重新分配数据复杂；添加数据库增加故障风险，需管理副本确保一致性。 
    - **键值存储系统（Key-Value Storage Systems）**
        - **适用场景**：适用于许多Web应用存储大量（数十亿甚至数万亿）相对小的记录（几KB到几MB），分布式文件系统不适合存储大量小文件，构建支持标准数据库特性（如外键约束和事务）的大规模并行关系数据库也困难。 
        - **系统特点**：提供通过关联键存储、更新和检索记录（值）的方式。并行键值存储将键划分到多台机器，路由更新和查找操作，支持副本并确保一致性，可按需添加机器并自动平衡负载。

### 键值存储系统（Key - Value Storage Systems）
- **功能特点**
    - 提供通过键存储、更新和检索记录（值）的方式，常用于Web应用存储大量小记录。并行键值存储将键划分到多台机器，路由操作，支持副本并确保一致性，可按需添加机器并自动平衡负载。
    - 通常不支持基于非键属性的记录检索（部分文档存储支持），为实现扩展性，多数系统牺牲一些数据库特性（如事务支持、SQL支持） ，但很多键值存储后来逐渐支持SQL和事务等特性。
    - 核心基于put(key, value)（存储值）和get(key)（检索值）两个基本函数，部分系统（如Bigtable）提供键值范围查询，文档存储支持有限的数据查询形式。
- **示例**
    - **MongoDB**：是一种文档存储类型的键值存储系统，使用JavaScript shell接口操作。示例代码如下：
```javascript
show dbs // 显示可用数据库
use sampledb // 使用数据库sampledb，若不存在则创建
db.createCollection("student") // 创建一个集合
db.createCollection("instructor")
show collections // 显示数据库中的所有集合

db.student.insert({ "id": "00128", "name": "Zhang",
    "dept_name": "Comp. Sci.", "tot_cred": 102, "advisors": ["45565"] })
db.student.insert({ "id": "12345", "name": "Shankar",
    "dept_name": "Comp. Sci.", "tot_cred": 32, "advisors": ["45565"] })
db.student.insert({ "id": "19991", "name": "Brandt",
    "dept_name": "History", "tot_cred": 80, "advisors": [] })
db.instructor.insert({ "id": "45565", "name": "Katz",
    "dept_name": "Comp. Sci.", "salary": 75000,
    "advisees": ["00128", "12345"] })

db.student.find() // 以JSON格式获取所有学生记录
db.student.findOne({"ID": "00128"}) // 查找匹配的单个学生记录

db.student.remove({"dept_name": "Comp. Sci."}) // 删除匹配的学生记录
db.student.drop() // 删除整个集合
```
    - **Bigtable**：谷歌的键值存储系统，HBase是其开源版本。数据值（记录）可包含多个属性，属性名集合不固定。记录标识符可分层结构化，如将URL映射为记录标识符。不原生支持JSON，但可将JSON数据映射到其数据模型。一个Bigtable实例可为多个应用存储数据，通过在记录标识符前添加应用名和表名区分。键实际由（记录标识符、属性名、时间戳）三部分组成，支持版本管理，查找时可指定数据项版本或选择最高版本号的版本。

### 并行和分布式数据库（Parallel and Distributed Databases）
- **定义与发展**：运行在多台机器（集群）上，设计用于跨多台机器存储数据和处理大型查询。20世纪80年代开始发展，早于现代大数据系统。从程序员角度看，使用方式类似单台机器上的数据库。
- **早期情况**：早期用于事务处理的并行数据库集群支持机器数量少，用于处理大型分析查询的支持数十到数百台机器。数据在集群多台机器上复制，防止数据丢失，查询处理中节点故障时，使用其他节点数据副本重新启动查询。
- **大规模集群问题**：在数千台机器集群上运行时，处理大量数据且长时间运行的查询在执行中发生故障概率显著增加，简单重启查询不再可行，避免完全重启的技术（如map-reduction系统中的技术）会引入显著开销，目前多数并行关系数据库系统仍针对数十到数百台机器的应用，故障时重启查询。

### 复制与一致性（Replication and Consistency）
- **复制的重要性**：复制是确保数据可用性的关键，对数据项的更新必须应用到其所有副本上，以保证即使存储数据项的部分机器故障，数据仍可访问。
- **面临的问题**
    - 一是确保更新多台机器数据的事务原子性执行，即故障时要么所有更新成功，要么所有数据项恢复到原始值。
    - 二是在数据项副本所在机器部分故障时，如何对已复制的数据项进行更新，要求所有活动副本具有相同值，每次读取能看到数据项最新版本（即一致性） 。
- **解决方案与权衡**：解决第二个问题的方案通常要求可用副本占多数来进行读写操作（如3个副本允许不超过1个故障，5个副本允许2个故障仍能保证多数副本可用） 。网络链路故障（如网络分区，两台活动机器无法通信）会带来额外问题，理论表明不存在协议能在网络分区情况下同时保证数据读写可用性和一致性，分布式系统需进行权衡，追求高可用性可能牺牲一致性（如允许读取旧值或副本值不同，之后通过合并更新使副本值一致） 。

### MapReduce范式（The MapReduce Paradigm）
- **基本概念**：MapReduce范式是并行处理中的一种常见模型。map()函数对大量输入记录进行处理，reduce()函数对map()函数的结果进行聚合操作。map()函数还可指定分组键，使reduce()函数在map()输出的每个分组内进行聚合 。该范式在函数式编程和并行处理领域有悠久历史，如Lisp语言就支持map和reduce函数。
- **使用原因**：以单词计数应用为例，处理大量文件时，顺序处理数据量过大不可行，编写并行程序需处理机器间任务协调、故障处理等复杂问题（即“管道”代码）。MapReduce系统为程序员提供指定应用核心逻辑的方式，由系统处理“管道”细节。程序员只需提供map()和reduce()函数，以及可选的数据读写函数，系统自动并行处理数据，程序员无需关注并行执行的复杂细节。该方法可用于多种处理大量数据的应用，如搜索引擎处理文档创建文本索引。
- **示例**
    - **单词计数（Word Count）**
        - **map()函数**：将输入记录（一般默认输入文件的每行）拆分为单个单词，输出（单词, 计数）对，计数初始为1。伪代码如下：
```
map(String record) {
    For each word in record
        emit(word, 1).
}
```
        - **处理过程**：MapReduce系统对map()函数输出的（键值对）进行排序或分组，将相同键（单词）的记录聚集在一起，形成（键, 列表）对，其中列表是该键对应的值的集合。
        - **reduce()函数**：对每个键（单词）对应的计数值列表进行累加，输出（单词, 总计数）对。伪代码如下：
```
reduce(String key, List value_list) {
    String word = key;
    int count = 0;
    For each value in value_list
        count = count + value
    output(word, count)
}
```
    - **日志处理（Log Processing）**：对于记录网站访问的日志文件，目标是统计特定目录下文件在指定日期范围内的访问次数。
        - **map()函数**：将输入记录（日志文件每行）拆分为日期、时间和文件名等字段，若日期在指定范围内，输出（文件名, 1） ，表示该文件名在记录中出现一次。
        - **reduce()函数**：将相同文件名对应的计数值累加，得到每个文件的总访问次数 。   

### MapReduce任务的并行处理（Parallel Processing of MapReduce Tasks）
- **并行执行机制**：MapReduce系统在多台机器上并行执行map()和reduce()函数。map任务处理部分数据（如部分文件或大文件的一部分） ，reduce任务处理部分reduce键。主节点将map()和reduce()代码发送给各任务，map任务执行代码并将输出数据按reduce键值排序分区后写入本地文件，reduce任务从网络获取相关文件，合并排序后将键值对输入reduce()函数。
- **文件输入输出并行化**：为避免单台机器存储数据成为瓶颈，MapReduce系统通过分布式文件系统（如Hadoop File System，HDFS）实现文件输入输出并行化。数据在多台机器存储并复制（一般复制3份） ，保障机器故障时数据仍可访问。如今，MapReduce系统通过存储适配器支持从多种大数据存储系统（如HBase、MongoDB、Cassandra、Amazon Dynamo）输入数据，输出也可发送到这些系统。

### Hadoop中的MapReduce（MapReduce in Hadoop）
- **实现特点**：Hadoop是用Java实现的广泛使用的MapReduce开源项目，也提供Python、C++等语言的API 。与伪代码不同，Hadoop实现需指定map()和reduce()函数输入输出键值类型。程序员需将map()和reduce()函数实现为继承Hadoop Mapper和Reducer类的成员函数。Hadoop允许指定文件拆分方式，如TextInputFormat将文件按行拆分，每行作为一个记录。对于压缩文件格式（如Avro、ORC、Parquet ） ，系统自动解压，程序员只需指定支持的类型。
- **combine()函数**：除reduce()函数外，Hadoop还允许定义combine()函数，在map任务执行节点执行部分reduce操作，减少网络传输数据量。以单词计数为例，combine()函数接收某个单词的部分计数列表，因reduce()函数是对值求和，所以使用combine()函数不影响最终结果。
- **多步骤执行**：Hadoop中一个MapReduce步骤包含一个map函数和一个reduce函数，程序可执行多个MapReduce步骤，前一步骤reduce()输出写入（分布式）文件系统供下一步骤读取。Hadoop还允许程序员控制作业中并行运行的map和reduce任务数量。 
- **Java实现示例**：以单词计数应用为例，定义实现Mapper接口和Reducer接口的两个类。Mapper和Reducer类是泛型类，接收输入键、输入值、输出键、输出值的类型参数。如实现Mapper接口的Map类类型定义中，map键类型为LongWritable（长整数） ，值类型为Text（文档部分或全部内容） ，map输出键类型为Text（单词） ，值类型为IntWritable（整数值） 。reduce()函数对每个reduce键值调用，第一个参数是reduce键本身，第二个参数是包含对应值的列表。

### Hadoop中单词计数程序的实现细节
- **map()函数**：在单词计数示例中，map()代码使用`StringTokenizer`将输入文本值拆分为单词，对于每个单词，调用`context.write(word, one)`输出键值对，其中`one`是数值为1的`IntWritable`对象 。
- **reduce()函数**：reduce()函数输入键类型与map输出键类型相同，输入值在示例中是`Java Iterable<IntWritable>`对象，包含map输出值列表。reduce()函数将接收到的值累加得到单词总计数，通过`context.write()`函数输出单词和总计数。
- **作业参数设置**：图10.9中的示例代码执行单个MapReduce作业，作业参数设置如下：
    - **设置map和reduce函数类**：通过`setMapperClass`和`setReducerClass`方法设置包含map和reduce函数的类。
    - **设置输出键值类型**：通过`setOutputKeyClass`和`setOutputValueClass`方法，分别将作业输出键类型设置为`Text`（单词） ，输出值类型设置为`IntWritable`（计数）。
    - **设置输入格式**：通过`job.setInputFormatClass`方法将作业输入格式设置为`TextInputFormat` ，其默认创建的map键值是文件中的字节偏移量（类型为`LongWritable`），map值是文件一行内容。程序员也可提供自定义输入格式类实现。
    - **设置输出格式**：通过`job.setOutputFormatClass`方法将作业输出格式设置为`TextOutputFormat`。
    - **设置输入输出路径**：通过`addInputPath`和`addOutputPath`方法设置输入文件存储目录和输出文件创建目录。
- **代码示例**：Hadoop中单词计数程序的Java实现代码如下：
```java
public class WordCount {
    public static class Map extends Mapper<LongWritable, Text, Text, IntWritable> {
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(LongWritable key, Text value, Context context)
                throws IOException, InterruptedException {
            String line = value.toString();
            StringTokenizer tokenizer = new StringTokenizer(line);
            while (tokenizer.hasMoreTokens()) {
                word.set(tokenizer.nextToken());
                context.write(word, one);
            }
        }
    }

    public static class Reduce extends Reducer<Text, IntWritable, Text, IntWritable> {
        public void reduce(Text key, Iterable<IntWritable> values, Context context)
                throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            context.write(key, new IntWritable(sum));
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = new Job(conf, "wordcount");

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        job.setMapperClass(Map.class);
        job.setReducerClass(Reduce.class);
        job.setInputFormatClass(TextInputFormat.class);
        job.setOutputFormatClass(TextOutputFormat.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));

        job.waitForCompletion(true);
    }
}
```
>日期：4.24

### MapReduce上的SQL（SQL on MapReduce）
- **适用场景**：MapReduce的许多应用用于并行处理大量非关系型数据，这些计算难以用SQL表达，如单词计数程序、网页搜索引擎的倒排索引计算、Google的PageRank计算等。但也有很多应用的逻辑可用SQL表达，若数据在数据库中，使用SQL编写查询并在并行数据库系统执行更方便。然而，很多应用数据在文件系统中，从文件加载数据到数据库存在时间和空间开销。
- **关系操作实现**：关系操作可通过map和reduce步骤实现。
    - **选择操作**：关系选择操作可由单个map()函数实现，无需reduce()函数（或reduce()函数简单输出输入，不做改变）。
    - **分组聚合操作**：关系分组和聚合函数可通过单个MapReduce步骤实现，map()输出以分组属性值作为reduce键的记录；reduce()函数接收特定分组键的所有属性值列表，并对列表值计算所需聚合。 
    - **连接操作**：连接操作（如等值连接）可通过单个MapReduce步骤实现。定义map()函数，对于每个输入记录分别输出包含连接属性和记录的对，并添加标签表明记录来源；reduce()函数针对每个连接属性值调用，分离不同关系的元组，输出它们的交叉乘积。
- **相关系统**：编写关系查询使用SQL更简洁易懂，新的系统允许在存储于文件系统的数据上并行执行SQL语言变体，如Apache Hive（最初在Facebook开发）、SCOPE（由微软开发）使用SQL变体，Apache Pig（最初在Yahoo!开发）使用基于关系代数的声明性语言Pig Latin 。这些系统允许直接从文件系统读取数据，程序员可定义函数将输入数据转换为记录格式，系统将包含map和reduce任务序列的程序编译并在MapReduce框架（如Hadoop）上执行，如今使用这些系统编写的查询远比直接使用MapReduce范式编写的多。Hive实现可将SQL代码编译为在并行环境执行的代数操作树，Apache Tez和Spark是支持在并行环境执行代数操作树（或有向无环图DAG）的广泛使用平台。

### 超越MapReduce：代数操作（Beyond MapReduce: Algebraic Operations）
- **动机**：关系操作可用map和reduce步骤表达，但这种方式很繁琐。例如计算两个输入的连接，程序员应能将其表达为单个代数操作，而非通过map和reduce函数间接表达。直接支持连接等操作可简化编程工作，且并行执行连接操作比使用map和reduce函数实现更高效。后来的并行数据处理系统增加了对其他关系操作（如外连接、半连接等变体）及多种支持数据分析操作的支持，许多机器学习模型和算法可建模为操作符，数据处理常涉及多个步骤，可建模为操作符序列（管道）或树，统一框架可将这些操作视为以一个或多个数据集为输入并输出一个或多个数据集的代数操作。
- **与关系代数的联系与区别**：关系代数是关系查询处理基础，将查询建模为操作树。后来的并行查询处理系统基于此思想，但有区别，关键区别在于输入数据可以是任意类型，而不仅是关系模型中的原子数据类型列 。

### Spark中的代数操作（Algebraic Operations in Spark）
- **Spark概述**：Apache Spark是广泛使用的并行数据处理系统，支持多种代数操作，数据可从多种存储系统输入或输出到多种存储系统。它使用弹性分布式数据集（Resilient Distributed Dataset，RDD）作为数据表示，RDD是可存储在多台机器上的记录集合，具有容错性，即便一台机器故障，也能从其他机器检索记录。Spark中的操作符以一个或多个RDD为输入，输出也是RDD，RDD中记录类型未预定义，可根据应用需求确定。Spark还支持称为DataSet的关系数据表示，后续会介绍。Spark提供Java、Scala和Python API。
- **单词计数程序示例**：图10.10展示了用Java和Apache Spark编写的单词计数程序，使用RDD数据表示，Java类型为JavaRDD 。RDD要求指定记录类型，示例中是Java字符串类型的RDD，还有JavaPairRDD类型用于存储具有指定类型的两个属性的记录，多个属性的记录可用结构化数据类型（如Tuple2、Tuple3、Tuple4 ，分别存储两个、三个、四个属性）表示。
    - **数据转换**：使用Spark处理数据的第一步是将数据从输入表示转换为RDD表示，通过`spark.read().textfile()`函数实现，该函数为输入的每行创建一个记录，输入可以是单个文件或包含多个文件的目录，Spark系统会在多台机器上对RDD进行分区，程序可将其视为单台机器上的数据结构，示例代码中结果是名为`lines`的RDD。
    - **单词拆分**：下一步是将每行拆分为单词数组，通过调用`flatMap()`函数实现。`flatMap()`类似于`map()`，但它调用用户定义函数返回一个迭代器，通过多次调用迭代器的`next()`函数获取多个值，最终返回包含所有输入记录值并集的RDD。示例代码使用Java 8的lambda表达式语法定义函数，如`s -> Arrays.asList(s.split(" ")).iterator()` ，该函数将输入字符串`s`按空格拆分后转换为列表并返回迭代器。
    - **创建键值对**：接下来创建名为`ones`的JavaPairRDD，其中包含形式为`(word, 1)`的键值对，每个单词对应一个这样的键值对。
    - **聚合操作**：最后通过`reduceByKey()`函数实现分组聚合操作，示例中传递lambda函数`(i1, i2) -> i1 + i2`给`reduceByKey()`函数，该函数对JavaPairRDD按第一个属性（单词）分组，使用提供的lambda函数聚合第二个属性（计数）的值。最终结果存储在名为`counts`的JavaPairRDD中。
    - **结果存储**：通过`saveAsTextFile()`函数将`counts` RDD存储到文件系统，如果RDD在机器间进行了分区，该函数会创建多个文件。
    - **并行处理原理**：理解Spark并行处理的关键在于，RDD可在多台机器上分区存储，每个操作可在多台机器上对本地可用的RDD分区并行执行。操作可能先对输入重新分区，将相关记录带到同一台机器再并行执行，例如`reduceByKey()`会重新分区输入RDD，将属于同一组的记录放在同一台机器上。
    - **延迟计算**：Spark中代数操作并非在函数调用时立即求值，代码实际创建一个操作树。例如示例代码中，`textFile()`从文件读取数据，`flatMap()`以`textFile()`操作为子操作，`mapToPairs()`又以`flatMap()`为子操作等。这些操作符可视为定义视图，在某些操作（如`saveAsTextFile()`、`collect()` ）要求时才对操作树求值。延迟计算的好处是在实际求值前，查询优化器可重写操作树以更快计算相同结果。一般情况下，操作可能形成有向无环图（Directed Acyclic Graph，DAG）结构，而非仅操作树结构。
- **DataSet类型**：RDD适合表示某些数据类型（如文本数据），但很多大数据应用需处理结构化数据，因此Spark引入DataSet类型，支持具有属性的记录，与Parquet、ORC和Avro等常用文件格式配合良好，这些格式用于以压缩方式存储具有多个属性的记录，Spark还支持从数据库读取关系的JDBC连接器。以下代码示例展示了如何读取和处理Parquet格式数据：
```scala
DataSet<Row> instructor = spark.read().parquet("...");
DataSet<Row> department = spark.read().parquet("...");
instructor.filter(instructor.col("salary").gt(100000))
    .join(department, instructor.col("dept_name")
        .equalTo(department.col("dept_name")))
    .groupBy(department.col("building"))
    .agg(count(instructor.col("ID")));
```
上述代码使用`Row`类型的DataSet，可通过名称访问列值。代码从Parquet文件读取`instructor`和`department`关系，Parquet文件存储列名等元数据，允许Spark为关系创建模式。然后对`instructor`关系应用过滤（选择）操作，保留工资大于100000的记录，再基于`dept_name`属性与`department`关系连接，按`building`属性分组，并对每个组计算`ID`值的数量。
- **自定义操作与Hive SQL支持**：定义新代数操作并在查询中使用的能力对许多应用很有用，促使Spark被广泛采用。Spark系统还支持将Hive SQL查询编译为Spark操作树并执行。
- **其他支持类型**：Spark允许除`Row`外的其他类与DataSet一起使用，对于自定义类，需定义`getAttrk()`和`setAttrk()`方法来检索和存储属性值。例如，若有`Instructor`类且Parquet文件属性与之匹配，可按以下方式读取数据：
```scala
DataSet<Instructor> instructor = spark.read().parquet("...")
    .as(Encoders.bean(Instructor.class));
```
此时Parquet提供输入文件属性名，用于将值映射到`Instructor`类属性。与`Row`不同，`Instructor`类属性类型在编译时已知，可更紧凑表示，还可使用类方法访问属性，避免运行时将属性名映射到记录位置的开销。
- **相关框架对比**：支持对复杂数据进行代数操作的框架中，最广泛使用的是Apache Tez和Apache Spark。Apache Tez提供适合系统实现者的低级API，如Hive on Tez将SQL查询编译为在Tez上运行的代数操作，Tez程序员可创建节点树（或一般的DAG）并提供在每个节点执行的代码，数据可在多台机器上分区，节点代码可在各机器执行，因Tez并非为应用程序员直接使用设计，未详细介绍。

### 流数据的应用场景（Applications of Streaming Data）
- **股票市场（Stock market）**：股票交易以元组形式表示并作为流发送到处理系统。交易者分析交易流寻找模式，据此做出买卖决策。早期系统实时要求为秒级，如今许多系统要求延迟在几十微秒，以便先于他人对相同模式做出反应。监管者也使用交易流，目的是检测非法活动模式，两者都需要持续查询模式，查询结果用于进一步行动。
- **电子商务（E-commerce）**：电商网站中，每次购买用元组表示，所有购买序列构成流，用户搜索行为即使未产生实际购买也有价值，也构成流。电商网站利用这些流实现多种目的，如实时监测广告活动对搜索和购买的影响、检测特定产品销售高峰并补货、监测用户频繁退货等行为模式并阻止其进一步退货或购买。
- **传感器（Sensors）**：传感器广泛应用于车辆、建筑和工厂等系统，定期发送读数形成流。流中的读数用于监测系统健康状况，异常读数时采取行动报警并检测修复潜在故障。根据系统复杂性和读数频率，流数据量可能很大，常由云端中央设施监测大量系统，并行处理对处理大量流入数据至关重要。
- **网络数据（Network data）**：管理大型计算机网络的组织需监测网络活动，检测网络问题和恶意软件攻击。监测数据以元组流表示，元组包含网络数据包源地址、目的地址、大小和生成时间戳等信息。由于元组生成速率极高，需用特殊硬件处理，或聚合数据降低生成速率。聚合流经处理检测问题，如链路故障、拒绝服务攻击、恶意软件传播等，且检测必须实时进行以便及时修复链路或阻止攻击。
- **社交媒体（Social media）**：如Facebook和Twitter等社交媒体接收用户消息流（如帖子或推文） ，每条消息需适当路由（如发送给朋友或关注者） ，可能传递给订阅者的消息按用户偏好、过往互动或广告费用排名后发送。社交媒体流不仅供人消费，也供软件分析，如公司监测提及公司的推文，负面情绪推文过多时发出警报，或分析广告活动对用户的影响。

### 流数据查询（Querying Streaming Data）
- **流数据特性与挑战**：数据库中存储的数据有时称为静态数据（data-at-rest） ，与流数据形成对比。流数据是无界的，理论上可能永远不会结束，因此那些需要看到流中所有元组才能输出结果的查询永远无法得出最终结果，例如查询流中元组数量就无法给出最终答案。
- **处理流数据无界性的方法**
    - **定义窗口（windows）**：处理流数据无界性的一种方法是在流上定义窗口，每个窗口包含具有特定时间戳范围或特定数量元组的记录。根据传入元组时间戳信息（如递增） ，可推断特定窗口内所有元组何时都已到达。一些流数据查询语言要求在流上定义窗口，查询可引用一个或几个窗口的元组，而非整个流。
    - **输出特定点结果并更新**：另一种选择是输出流中特定点正确的结果，并在更多元组到达时更新结果。例如计数查询可输出特定时间点看到的元组数量，新元组到达时根据新计数更新结果。
- **流数据查询的几种方法**
    - **连续查询（Continuous queries）**：将传入数据流视为对关系的插入操作，可使用SQL或关系代数操作编写对关系的查询，并将这些查询注册为连续查询，即持续运行的查询。系统启动时输出初始数据查询结果，每个传入元组可能导致连续查询结果中元组的插入、更新或删除，连续查询的输出是查询结果更新流，底层数据库随传入流更新。此方法在用户希望查看满足某些条件的所有数据库插入操作的应用中有益，但输入速率高时，查询结果使用者会收到大量连续查询更新，尤其对于输出聚合值的应用不太理想，用户可能希望看到一段时间的最终聚合值，而非每个传入元组插入时的中间结果。
    - **流查询语言（Stream query languages）**：通过扩展SQL或关系代数定义查询语言，将流与存储关系区别对待。大多数流查询语言使用窗口操作，应用于流并创建与窗口内容对应的关系。例如，对流的窗口操作可按每天的每小时创建元组集，每个集就是一个关系，可对每个元组集执行关系操作（包括聚合、选择以及与存储关系数据或其他流窗口连接）以生成输出。流查询语言在语言层面将流数据与存储关系分开，执行关系操作前需应用窗口操作，确保仅查看流的一部分就能输出结果。若流保证元组时间戳递增，看到时间戳高于窗口结束时间的元组时，可推断基于时间的窗口不再有更多元组，此时可输出窗口聚合结果。有些流不保证时间戳递增，但包含标点（punctuations） ，即声明所有未来元组时间戳大于某个值的元数据元组，标点定期发出，窗口操作符可用其确定聚合结果（如每小时窗口聚合）何时完成并输出。
    - **流上的代数操作符（Algebraic operators on streams）**：允许用户编写对每个传入元组执行的操作符（用户定义函数） 。元组从输入路由到操作符，操作符输出可路由到另一个操作符、系统输出或存储在数据库中。操作符可在处理元组时维护内部状态，聚合传入数据，也可将数据持久存储在数据库中供长期使用，近年来此方法得到广泛应用。
    - **模式匹配（Pattern matching）**：定义模式匹配语言，允许用户编写多个规则，每个规则包含一个模式和一个操作。系统找到与特定模式匹配的元组子序列时，执行与该模式对应的操作，此类系统称为复杂事件处理（Complex Event Processing，CEP）系统，流行的复杂事件处理系统包括Oracle Event Processing、Microsoft StreamInsight和FlinkCEP（Apache Flink项目一部分）。

### 流处理系统架构与SQL扩展
- **流处理系统架构**：许多流处理系统将数据保存在内存中，不提供持久性保证，目标是以最小延迟生成结果，以便基于流数据分析快速响应。另一方面，传入数据可能也需要存储在数据库中供后续处理。为支持这两种查询模式，许多应用使用所谓的lambda架构，即将输入数据副本提供给流处理系统，另一个副本提供给数据库存储和后续处理。但这种架构存在问题，如查询可能需要用不同语言为流处理系统和数据库系统编写两次，流查询可能无法高效访问存储数据。支持流查询以及持久存储和跨流与存储数据查询的系统可避免这些问题。
- **SQL对流的扩展（Stream Extensions to SQL）**：SQL窗口操作在之前章节有描述，但流查询语言支持SQL窗口函数不支持的更多窗口类型。常见支持的窗口函数包括：
    - **滚动窗口（Tumbling window）**：每小时窗口是滚动窗口的例子，窗口不重叠但彼此相邻，通过窗口大小（如小时数、分钟数或秒数）指定。
    - **跳跃窗口（Hopping window）**：每20分钟计算一次的每小时窗口是跳跃窗口的例子，窗口宽度固定（与滚动窗口类似） ，但相邻窗口可以重叠。 
    - **滑动窗口（Sliding window）**：围绕每个传入元组的指定大小（基于时间或元组数量）的窗口，SQL标准支持此类型窗口。 
    - **会话窗口（Session window）**：模拟用户在会话中执行多个操作，窗口由用户和超时时间间隔标识，包含在超时时间间隔内发生的一系列操作。例如超时时间为5分钟，用户在10点执行一个操作，10:04执行第二个操作，11点执行第三个操作，则前两个操作属于一个会话，第三个操作属于不同会话。也可指定最大持续时间，达到该持续时间后，即使在超时时间间隔内有操作执行，会话窗口也会关闭。指定窗口的确切语法因实现而异，假设有关系`order(orderid, datetime, itemid, amount)` ，在Azure Stream Analytics中，按每小时计算每个商品的总订单金额可通过滚动窗口指定。

### 流上的代数操作（Algebraic Operations on Streams）
- **适用场景与操作符**：SQL查询对流数据处理虽有用，但在许多场景不适用。流处理的代数操作方法允许提供用户定义代码实现代数操作，同时也提供如选择和窗口聚合等预定义代数操作。
- **计算执行与路由**：执行计算时，传入元组需路由到消耗元组的操作符，操作符输出需路由到其消费者。实现的关键任务是在系统输入、操作符和输出之间提供容错的元组路由。Apache Storm和Kafka是支持此类数据路由的广泛使用的实现。
- **逻辑路由实现方式**
    - **有向无环图（DAG）**：元组逻辑路由通过创建以操作符为节点的有向无环图（DAG）实现，节点间边定义元组流。每个操作符输出的元组沿其出边发送到消费操作符，每个操作符从入边接收元组。图10.11a展示了通过DAG结构对流元组的逻辑路由，操作节点用“Op”表示，流处理系统入口点是DAG的数据源节点，从流源消耗元组并注入系统；出口点是数据汇聚节点，通过数据汇聚离开系统的元组可存储在数据存储或文件系统中，或以其他方式输出。一种实现流处理系统的方式是将图作为系统配置一部分指定，系统开始处理元组时读取该配置用于路由元组，Apache Storm流处理系统就是使用配置文件（在Storm系统中称为拓扑）定义图的例子，数据源节点称为spouts，操作符节点称为bolts，边连接这些节点。
    - **发布 - 订阅系统（Publish - Subscribe）**：另一种实现路由图的方式是使用发布 - 订阅系统。发布 - 订阅系统允许发布与特定主题相关联的文档或其他形式的数据，订阅者相应订阅指定主题。文档发布到特定主题时，副本会发送给所有订阅该主题的订阅者，也简称为pub - sub系统。在流处理系统中使用发布 - 订阅系统路由元组时，元组视为文档，每个元组标记一个主题。系统入口概念上“发布”元组（每个元组关联一个主题） ，操作符订阅一个或多个主题，系统将特定主题的所有元组路由给订阅该主题的所有操作符，操作符也可将输出发布回发布 - 订阅系统并关联主题。发布 - 订阅方法的主要优点是可相对轻松地向系统添加或从系统删除操作符。图10.11b展示了使用发布 - 订阅表示的元组路由，每个数据源分配唯一主题名，操作符输出也分配唯一主题名，每个操作符订阅其输入发布的主题并发布其输出对应的主题，数据源向关联主题发布，数据汇聚订阅操作符输出到汇聚的主题。Apache Kafka系统使用发布 - 订阅模型管理流中元组路由，为主题发布的元组在指定时间段（保留期）内保留，即使当前无该主题订阅者。订阅者通常尽早处理元组，处理因故障延迟或暂时停止时，元组在保留期到期前仍可处理。
- **不同流处理系统实现**
    - **Apache Spark**：允许将流数据源用作操作输入，但部分操作可能在消耗完整个流才输出结果，这可能需无限长时间。为避免此问题，Spark将流分解为离散化流（discretized streams） ，特定时间窗口的流数据视为代数操作符的数据输入，窗口内数据消耗完后，操作符生成输出，就像数据源是文件或关系时一样。
    - **Apache Storm和Apache Flink**：支持以流为输入并输出另一个流的流操作，对于map或关系选择等操作很直接，每个输出元组从输入元组继承时间戳。但关系聚合操作和归约操作可能在消耗完整个流才生成输出，为支持此类操作，Flink支持窗口操作，将流分解为窗口，在每个窗口内计算聚合，窗口完成时输出，输出视为流，元组时间戳基于窗口结束时间。 

### 图数据库（Graph Databases）
- **图数据的重要性与建模示例**：图是数据库需处理的重要数据类型。例如，有多个路由器及它们之间链路的计算机网络，可将路由器建模为节点，网络链路建模为边；道路网络可将道路交叉点建模为节点，交叉点间道路链路建模为边；带有超链接的网页可将网页建模为节点，超链接建模为边。在企业的E - R模型中，每个实体可建模为图的节点，每个二元关系可建模为图的边，三元及更高阶关系若需要可建模为一组二元关系。
- **图在关系模型中的表示**：图可使用关系模型通过以下两个关系表示：
    - `node(ID, label, node_data)`
    - `edge(fromID, toID, label, edge_data)`
其中`node_data`和`edge_data`分别包含与节点和边相关的所有数据。然而，仅用这两个关系对复杂数据库模式建模过于简单，实际应用中可使用多个关系存储不同类型的节点和边。
- **图数据库的特性**：尽管图数据可轻松存储在关系数据库中，但像广泛使用的Neo4j这样的图数据库提供了一些额外特性：
    - 允许识别表示节点或边的关系，并提供定义此类关系的特殊语法。
    - 支持专为轻松表达路径查询而设计的查询语言，这些查询在SQL中可能更难表达。
    - 为此类查询提供高效实现，执行速度比在常规数据库上用SQL表达和执行的查询快得多。
    - 为图可视化等其他功能提供支持。 
- **图查询示例（Neo4j的Cypher语言）**
    - **查询导师和学生关系**：假设输入图中有对应学生（存储在`student`关系中）和导师（存储在`instructor`关系中）的节点，以及从学生到导师的`advisor`类型边。使用Cypher语言编写查询如下：
```cypher
match (i:instructor)<-[:advisor]-(s:student)
where i.dept_name= 'Comp. Sci.'
return i.ID as ID, i.name as name, collect(s.name) as advisees
```
`match`子句通过`advisor`关系（建模为反向遍历`advisor`边的图路径）连接导师和学生，基本执行导师、`advisor`和学生关系的连接。然后按导师ID和姓名分组，将导师指导的所有学生收集到名为`advisees`的集合中。 
    - **查询课程先修关系**：Neo4j还支持边的递归遍历。假设要查找课程的直接和间接先修课程，`course`关系建模为节点类型，`prereq(course_id, prereq_id)`关系建模为边类型，查询如下：
```cypher
match (c1:course)-[:prereq *1..]->(c2:course)
return c1.course_id, c2.course_id
```
这里`*1..`表示考虑包含多个`prereq`边的路径，最少1条边（最少为0时课程本身可视为自己的先修课程）。 
- **大规模图的并行处理方法**
    - **Map - reduce和代数框架**：图可表示为关系，许多并行图算法的单个步骤可表示为连接。图可存储在并行存储系统中，跨多台机器分区，然后使用map - reduce程序、如Spark等代数框架或并行关系数据库实现，在多个节点上并行处理图算法的每个步骤。此方法适用于许多应用，但对于迭代计算（如遍历图中长路径）效率低，因每次迭代通常需读取整个图。 
    - **批量同步处理框架（Bulk Synchronous Processing, BSP）**：图算法的BSP框架将图算法构建为与以迭代方式操作的顶点相关联的计算。与前一种方法不同，图通常存储在内存中，顶点跨多台机器分区，最重要的是每次迭代无需读取整个图。

### 现代数据管理特点
- 现代数据管理应用常需处理非关系形式的数据，且数据量远超传统组织产生的数据量。
- 数据传感器使用增加，促使传感器及嵌入其他物体的计算设备与互联网连接，即“物联网”。
- 大数据应用的查询语言选择更为多样，这受处理更多样数据类型及应对大规模数据量/流速需求的驱动。
- 构建能应对大数据量/流速的数据管理系统，需数据的并行存储和处理。

### 分布式存储系统
- **分布式文件系统**：允许文件存储在多台机器上，同时可通过传统文件系统接口访问文件。
- **键值存储系统**：可基于键存储和检索记录，可能提供有限查询功能，并非成熟数据库系统，有时称为NoSQL系统。
- **并行和分布式数据库**：提供传统数据库接口，但数据存储在多台机器上，查询处理在多台机器上并行进行。

### MapReduce范式
- MapReduce范式为并行处理中的常见情况建模，`map()`函数对大量输入记录进行处理，`reduce()`函数对`map()`函数的结果进行聚合。
- Hadoop系统是用Java语言实现的广泛使用的MapReduce开源框架。
- 大量应用使用MapReduce范式进行各种数据处理，其逻辑可用SQL轻松表达。

### 关系代数与复杂数据处理
- 关系代数是关系查询处理的基础，可将查询建模为操作树。该理念扩展到更复杂数据类型场景，支持能处理含复杂数据类型记录数据集的代数操作符，并返回含类似复杂数据类型记录的数据集。

### 流数据处理
- 许多应用需对连续到达的数据持续执行查询，流数据即指连续到达的数据，众多应用领域需实时处理传入数据。

### 图数据库与图处理
- **图数据重要性**：图是数据库需处理的重要数据类型。
- **图的表示与存储**：图可使用关系模型通过`node(ID, label, node_data)`和`edge(fromID, toID, label, edge_data)`两个关系表示，但对于复杂数据库模式，可使用多个关系存储不同类型节点和边。像Neo4j这样的图数据库提供额外特性，如识别节点或边关系的特殊语法、支持便于表达路径查询的查询语言、高效查询实现及图可视化支持等。
- **图查询示例**
    - **Neo4j的Cypher语言**：在Neo4j的Cypher语言中，查询导师和学生关系的示例代码为：
```cypher
match (i:instructor)<-[:advisor]-(s:student)
where i.dept_name= 'Comp. Sci.'
return i.ID as ID, i.name as name, collect(s.name) as advisees
```
查询课程先修关系的示例代码为：
```cypher
match (c1:course)-[:prereq *1..]->(c2:course)
return c1.course_id, c2.course_id
```
- **图的并行处理框架**
    - **批量同步处理框架（BSP）**：图算法的BSP框架中，图的每个顶点（节点）关联数据（状态）。程序员为图的每个节点提供执行方法，这些方法可向相邻节点发送和接收消息。在每次迭代（超步，superstep）中，执行与每个节点关联的方法，该方法处理传入消息、更新节点关联数据，还可选择向相邻节点发送消息。当前迭代发送的消息在下一迭代被接收。每个顶点的方法可投票决定是否停止计算，若某次迭代所有顶点都投票停止且无消息发出，计算即可停止。计算结果包含在每个节点的状态中，可收集并输出。批量同步处理理念由来已久，Google开发的Pregel系统使其流行，该系统提供了框架的容错实现，Apache Giraph系统是Pregel系统的开源版本。
    - **Apache Spark的GraphX组件**：支持大规模图的图计算，提供基于Pregel的API及其他以图为输入输出图的操作，包括对图顶点和边应用map函数、图与RDD的连接，以及一种聚合操作（使用用户定义函数创建发送给节点所有邻居的消息，另一个用户定义函数聚合消息） ，这些操作可并行执行以处理大规模图。

>日期：4.26
课后习题选做  
### 10.10
1. **个性化推荐**：根据用户浏览网页记录，分析其兴趣偏好，为用户推荐相关的产品、内容或服务。例如电商网站根据用户浏览过的商品，推荐类似或互补商品。
2. **流量分析与优化**：统计不同网页的访问量、访问时长等信息，分析用户在网站内的浏览路径。据此优化网站结构和页面布局，提升用户体验和网站流量转化率。
3. **广告投放优化**：了解用户访问页面内容和行为，精准投放广告。比如用户常浏览科技类页面，就推送科技产品广告，提高广告点击率和投放效果。 
4. **用户行为分析与留存**：分析用户登录、访问频率等行为，评估用户活跃度和忠诚度。对于访问频率降低的用户，采取召回策略，如发送个性化邮件或推送通知，提高用户留存率。 

### 10.11
大数据的数据多样性体现在数据类型、结构和来源等多方面。SQL主要适用于处理结构化数据，对于非结构化（如文本、图像、音频等）和半结构化（如JSON、XML等）数据处理能力有限。大数据中大量存在这些非传统结构化数据，需要专门的工具和语言来处理。例如，处理文本数据时，需要使用文本分析工具和相关语言进行词法、句法分析、情感分析等；处理图像数据时，要借助图像处理库和编程语言来提取特征、进行图像识别。而且不同来源的数据格式和存储方式各异，SQL难以满足多样化的存储和查询需求，因此需要其他语言和工具来应对大数据的多样性。 

### 10.12
1. **数据库分区**：将数据水平分割成多个分区，分布到不同存储设备或服务器上。例如按时间范围分区，将不同时间段的数据存储在不同分区，减轻单个服务器负载，提高查询效率。
2. **引入分布式数据库**：采用分布式数据库系统，将数据分散存储在多个节点上，节点间并行处理查询和事务。如Cassandra、MongoDB等，可根据数据量和访问模式进行节点扩展，提升系统处理能力。 
3. **使用缓存机制**：在应用层或数据库层添加缓存，如Redis。将频繁访问的数据（如热门商品信息、用户登录信息等）存储在缓存中，减少对数据库的直接访问，加快响应速度。 
4. **优化查询语句**：对现有的SQL查询进行优化，分析查询执行计划，调整索引策略，避免全表扫描等低效操作。例如，为经常用于查询条件的字段添加索引，提高查询效率。 

### 10.13
**Map函数伪代码**：
```python
def map(context):
    doc_id = context.getDocumentID()
    line = context.getInput()
    words = line.split()
    for word in words:
        context.write(word, doc_id)
```
**Reduce函数伪代码**：
```python
def reduce(key, values):
    doc_id_list = []
    for value in values:
        doc_id_list.append(value)
    result = ",".join(str(doc_id) for doc_id in doc_id_list)
    context.write(key, result)
```

### 10.14
1. `flatMap`
2. `iterator`
3. `Tuple2(word, 1)`

### 10.15
流应提供标点（punctuations）信息，即元数据元组，声明所有未来元组的时间戳将大于某个值。通过这些标点信息，流查询处理系统可以确定在某个窗口内的所有元组是否都已到达，进而决定何时对窗口内的数据进行处理。 

### 10.16
在基于发布 - 订阅系统（如Apache Kafka）对流执行多个操作时：
1. **数据发布**：数据源将元组作为文档发布到关联主题。每个元组标记特定主题，数据源根据数据类型或属性等规则，确定元组所属主题并发布。例如，电商订单流数据可按订单类型（如普通订单、退货订单等）划分主题。
2. **操作符订阅**：操作符订阅一个或多个主题。不同操作符根据自身功能需求订阅相关主题，如用于分析订单金额的操作符订阅包含订单金额信息的主题。操作符接收订阅主题的所有元组。
3. **元组处理与发布**：操作符对接收的元组进行处理，如计算、过滤、转换等。处理完成后，操作符可将输出作为新的元组发布回发布 - 订阅系统，并关联新的主题。例如，订单金额分析操作符处理完数据后，将分析结果发布到“订单金额分析结果”主题。
4. **后续操作与汇聚**：其他操作符可订阅这些新主题，继续对数据进行处理。最终，数据汇聚订阅相关操作符输出的主题，获取处理后的数据，完成整个流数据的多操作处理流程。 













