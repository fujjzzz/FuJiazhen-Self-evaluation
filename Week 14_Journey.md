本周阅读**Database-System-Concepts-7th-Edition**:PART SIX QUERY PROCESSING AND OPTIMIZATION,知识点总结如下：  
**Chapter 15 Query Processing**(p689-740)  
>日期：5.27

# 第15章 查询处理

## 15.1 概述
查询处理指从数据库中提取数据所涉及的一系列活动。这些活动包括将高级数据库语言编写的查询，转换为可在文件系统物理层面使用的表达式、进行各种查询优化转换，以及对查询进行实际评估。
查询处理的基本步骤如下：
1. **解析与转换**：将查询（如SQL）转换为基于扩展关系代数的内部形式。解析器会检查用户查询的语法，验证查询中出现的关系名称是否为数据库中的关系名等。系统构建查询的语法树表示，然后将其转换为关系代数表达式。若查询基于视图表示，转换阶段还会用定义视图的关系代数表达式替换所有视图引用。
2. **优化**：构建能使查询评估成本最小化的查询评估计划。 
3. **评估**：执行查询评估计划并返回结果。 

## 15.2 查询成本度量
- **成本构成**：查询评估成本可从磁盘访问、CPU时间以及（在并行和分布式系统中的）通信成本等方面衡量。对于大型磁盘数据库，I/O成本通常占主导。随着闪存存储（固态硬盘，SSDs）的兴起和主内存容量增大，CPU成本也需纳入考量。 
- **成本估算因素**： 
    - 我们使用从存储中传输的块数（ $b$ ）和随机I/O访问次数（ $S$ ）。一次操作所需时间为 $b * t_T+S * t_S$ ，其中 $t_T$ 是传输一块数据的时间， $t_S$ 是平均块访问时间（对于磁盘，是磁盘寻道时间加上旋转延迟 ）。
    - 2018年高端磁盘的典型值为 $t_S = 4$ 毫秒， $t_T = 0.1$ 毫秒（假设块大小为4KB，传输速率为每秒40MB ）。 
    - 2018年使用SATA接口的中端SSD， $t_S$ 约为90微秒，对于4KB的块， $t_T$  约为10微秒。使用PCIe 3.0 x4接口的SSD， $t_S$ 更小（20 - 60微秒），传输速率更高（ $t_T$ 为2微秒 ）。 
    - 对于主内存中的数据，传输4KB块的时间 $t_T$ 小于1微秒，获取数据的延迟  $t_S$ 小于100纳秒。 
- **缓冲区影响**：算法成本取决于主内存中缓冲区的大小。在PostgreSQL中，出于成本估算目的，查询的有效缓存大小（查询可用的总内存）默认假定为4GB。若多个操作符并发运行，可用内存将在它们之间分配。为考虑缓冲区驻留情况，PostgreSQL假定随机页面读取成本为实际成本的1/10，以模拟90%的缓存命中率。 
- **响应时间与资源消耗**：响应时间（执行计划的实际时间）难以估算，因为它取决于查询开始时缓冲区的内容，以及多磁盘系统中的磁盘访问分布情况。因此，优化器通常旨在最小化查询计划的总资源消耗，比如估算总磁盘访问时间（包括寻道和数据传输 ）。 

## 15.3 选择操作
- **文件扫描**：在查询处理中，文件扫描是访问数据的最底层操作符。它是一种搜索算法，用于定位和检索满足选择条件的记录。在关系系统中，当关系存储在单个文件中时，可使用文件扫描读取整个关系。 
- **使用文件扫描和索引的选择操作**： 
    - **A1（线性搜索）**：扫描每个文件块，并测试所有记录是否满足选择条件。需要初始寻道来访问文件的第一个块。尽管它可能比其他实现选择操作的算法慢，但无论文件顺序、索引可用性或选择操作的性质如何，都可应用于任何文件。 

SQL查询示例：
```sql
select salary
from instructor
where salary < 75000;
```
此查询可转换为以下关系代数表达式：
- $\sigma_{salary<75000} (\Pi_{salary} (instructor))$
- $\Pi_{salary} (\sigma_{salary<75000} (instructor))$ 

### 15.3 选择操作
- **文件扫描基础**：文件扫描是查询处理中访问数据的底层操作符，用于定位和检索满足选择条件的记录。在关系系统中，当关系存储在单个文件时可使用。
- **选择算法及成本估算**
    - **A1（线性搜索）**
        - **一般情况**：成本公式为  $t_S + b_r * t_T$  。需一次初始寻道加上  $b_r$  次块传输 ， $b_r$  是文件中的块数。
        - **键上相等条件平均情况**：成本公式为  $t_S+(b_r/2) * t_T$  。因为最多只有一条记录满足条件，找到所需记录后扫描可终止，平均需扫描一半块 ，但最坏情况仍需传输  $b_r$  个块。
    - **A2（聚簇索引，键上相等）**：利用聚簇索引检索满足键相等条件的单个记录。成本公式为  $(h_i + 1) * (t_T + t_S)$  ， $h_i$  是索引树高度 。索引查找需遍历树高对应层数再加一次I/O获取记录，每次I/O操作包含一次寻道和一次块传输。为模拟索引内部节点在内存缓冲区的常见情况，可设  $h_i = 1$  。
    - **A3（聚簇索引，非键上相等）**：用聚簇索引检索满足非键属性相等选择条件的多个记录。记录在文件中按搜索键顺序存储。成本公式为  $h_i * (t_T + t_S) + t_S + b * t_T$  ， $h_i$  是索引树高度， $b$  是包含指定搜索键记录的块数 。需对树的每一层进行一次寻道，加上获取第一个块的寻道，然后读取包含记录的块。
    - **A4（辅助索引，相等）**
        - **键上相等**：检索单个记录，成本与聚簇索引情况A2相同，即  $(h_i + 1) * (t_T + t_S)$  。
        - **非键上相等**：可能检索多个记录，每个记录可能在不同块，每次I/O操作需寻道和块传输。最坏情况成本公式为 $(h_i + n) * (t_S + t_T)$ ， $n$ 是获取的记录数 。若内存缓冲区大，记录所在块可能已在缓冲区，可通过考虑记录在缓冲区的概率来估算平均成本，此时成本会远低于最坏情况。
    - **A5（聚簇索引，比较）**
        - 对于  $A \geq v$  或  $A > v$   形式的比较条件，使用聚簇索引定位满足条件的元组。成本估算与A3相同。如  $A \geq v$  时，从索引查找第一个  $A \geq v$ 的元组，然后从该元组开始扫描文件； $A > v$ 时，从第一个 $A > v$  的元组开始扫描 。
        - 对于  $A < v$ 或 $A \leq v$ 形式的比较条件，无需索引查找。 $A < v$ 时从文件开头扫描到第一个 $A = v$ 的元组前； $A \leq v$ 时类似，扫描到第一个  $A > v$  的元组前 。
    - **A6（辅助索引，比较）**：用辅助有序索引处理涉及  $<$ 、 $\leq$ 、 $\geq$ 、 $>$  的比较条件。扫描最低层索引块， $<$  和  $\leq$  从最小值到  $v$  扫描， $>$  和  $\geq$  从  $v$  到最大值扫描 。辅助索引提供记录指针，但获取实际记录可能需为每个记录进行一次I/O操作（因连续记录可能在不同磁盘块），若检索记录数多，可能比线性搜索更昂贵，所以仅在检索记录少的情况使用 。
- **位图索引扫描（PostgreSQL）**：当辅助索引可用但匹配记录数不确定时，PostgreSQL使用位图索引扫描算法。先创建与关系中块数相同位数的位图并初始化为0 ，通过辅助索引找到匹配元组的索引项，将对应块号的位设置为1 。处理完所有索引项后，扫描位图找到位为1的块（即包含匹配记录的块），然后线性扫描关系，跳过位不为1的块，只获取位为1的块并扫描块内记录。最坏情况比线性扫描略贵，最好情况比线性扫描和辅助索引扫描都便宜很多，保证性能不会比最佳方案差太多 。
- **复杂选择实现**
    - **合取选择**：形式为  $\sigma_{\theta_1 \land \theta_2 \land \cdots \land \theta_n}(r)$  。
    - **析取选择**：形式为  $\sigma_{\theta_1 \lor \theta_2 \lor \cdots \lor \theta_n}(r)$  ，由满足单个简单条件  $\theta_i$  的所有记录的并集满足 。
    - **否定选择**： $\sigma_{\neg \theta}(r)$  的结果是 $r$ 中使条件  $\theta$ 为假的元组集合，无空值时是  $r$  中不在  $\sigma_{\theta}(r)$ 中的元组集合 。
    - **实现算法**：如A7（使用一个索引的合取选择），先确定简单条件中是否有属性存在访问路径，若有则使用相应索引算法，一般比线性搜索快 。
- **索引相关概念**
    - **索引结构**：即访问路径，可定位和访问数据。
    - **聚簇索引**：也叫主索引，能让文件记录按与物理顺序对应的顺序读取 。
    - **辅助索引/非聚簇索引**：非聚簇索引 。
    - **索引扫描**：使用索引的搜索算法，通过选择谓词指导选择处理查询时使用的索引。

### 15.4 排序
- **排序的重要性**：在数据库系统中，数据排序很重要，一是SQL查询可指定输出排序，二是一些关系操作（如连接）在输入关系先排序时能更高效实现。
- **排序方式及问题**：可通过在排序键上建索引并按序读取关系来排序，但这种逻辑排序方式可能导致每条记录都需磁盘访问（寻道 + 块传输），代价高，所以有时需物理排序。
- **外部排序 - 归并算法（External Sort - Merge Algorithm）**
    - **第一阶段（创建排序段）**：设 $M$ 是主存缓冲区可用于排序的块数。重复读取关系的 $M$ 个块（或剩余块），对内存中的部分排序，写入排序文件 $R_i$ ，直到处理完整个关系。
    - **第二阶段（合并排序段）**：若排序段总数 $N$ 小于 $M$ ，为每个段分配一个块并预留一个输出块空间。从每个文件 $R_i$ 读取一个块到内存缓冲区，重复选择所有缓冲区中排序顺序的第一个元组写入输出并删除，若某个段缓冲区为空且文件未结束，则读取下一个块，直到所有输入缓冲区为空。一般情况下，关系大时会产生 $M$ 个或更多排序段，合并需多趟进行，每趟合并 $M - 1$ 个排序段，直到排序段数小于 $M$ ，最后一趟生成排序输出。
- **外部排序 - 归并的成本分析**
    - **磁盘块传输成本**：设 $b_r$ 是包含关系 $r$ 记录的块数，初始阶段读和写块共 $2b_r$ 次传输。初始排序段数为 $\lceil b_r / M\rceil$ 。合并时，为减少寻道，每次读写较多块（设为 $b_b$ ），每趟合并可减少 $\lfloor M / b_b\rfloor - 1$ 个排序段，总合并趟数为 $\lceil\log_{\lfloor M / b_b\rfloor - 1}(b_r / M)\rceil$ 。除最后一趟可能不写回磁盘及部分排序段可能不参与某趟读写外，总块传输数为 $b_r(2\lceil\log_{\lfloor M / b_b\rfloor - 1}(b_r / M)\rceil + 1)$ 。
    - **磁盘寻道成本**：生成排序段及合并过程都需寻道，总寻道数为 $2\lceil b_r / M\rceil + \lceil b_r / b_b\rceil(2\lceil\log_{\lfloor M / b_b\rfloor - 1}(b_r / M)\rceil - 1)$ 。
>日期：5.28  

### 15.5 连接操作
- **等值连接（equi - join）**：指形式为 $r \bowtie_{r.A = s.B} s$ 的连接，其中 $A$ 和 $B$ 分别是关系 $r$ 和 $s$ 的属性或属性集。
- **嵌套循环连接（Nested - Loop Join）**
    - **算法原理**：由一对嵌套的for循环组成，关系 $r$ 为外关系，关系 $s$ 为内关系。用 $t_r \cdot t_s$ 表示连接后的元组。该算法无需索引，适用于任何连接条件，扩展计算自然连接只需在结果中删除重复属性。
    - **成本分析**：需考虑的元组对数量为 $n_r * n_s$ （ $n_r$ 、 $n_s$ 分别是 $r$ 、 $s$ 中的元组数）。最坏情况下，缓冲区只能存每个关系的一个块，需 $n_r * b_s + b_r$ 次块传输（ $b_r$ 、 $b_s$ 分别是 $r$ 、$s$ 的块数）， $n_r + b_r$ 次寻道；最好情况下，两关系都能同时存于内存，只需 $b_r + b_s$ 次块传输和两次寻道。若一个关系能完全存入主存，将其作为内关系可减少传输和寻道次数。

### 选择操作算法补充
- **A8（使用复合索引的合取选择）**：对于某些合取选择，若有合适的复合索引（多个属性上的索引），且选择在两个或更多属性上指定相等条件，可直接搜索索引，根据索引类型确定使用A2、A3或A4算法。
- **A9（通过标识符交集的合取选择）**：涉及使用记录指针或标识符的索引，扫描每个索引获取满足单个条件的元组指针，取指针交集得到满足合取条件的元组指针，再用指针获取实际记录。成本是单个索引扫描成本加上检索指针交集记录的成本，对指针列表排序可降低成本。
- **A10（通过标识符并集的析取选择）**：若析取选择的所有条件都有访问路径，扫描每个索引获取满足单个条件的元组指针，取指针并集得到满足析取条件的元组指针，再用指针获取实际记录。若有一个条件无访问路径，则需对关系进行线性扫描。  
- **块嵌套循环连接（Block Nested - Loop Join）**
    - **算法原理**：嵌套循环连接的变体，内关系的每个块与外关系的每个块配对，在每对块内元组两两配对生成所有元组对，满足连接条件的元组对加入结果。
    - **成本分析**：最坏情况下，内关系 $s$ 的每个块针对外关系 $r$ 的每个块读一次，块传输总数为 $b_r * b_s + b_r$ （ $b_r$ 、$b_s$ 分别是 $r$、$s$ 的块数），内关系每次扫描需一次寻道，外关系扫描每块需一次寻道，总寻道数为 $2 * b_r$ 。最好情况（内关系能存于内存）下，块传输数为 $b_r + b_s$ ，寻道数为两次。以 `student ⋈ takes` 为例，最坏情况块传输40,100次，寻道200次，相比基本嵌套循环连接有显著改善，最好情况成本不变，即500次块传输和两次寻道。
    - **性能提升策略**
        - 若自然连接或等值连接的连接属性在内关系构成键，外关系元组找到第一个匹配时内循环可终止。
        - 块嵌套循环算法中，外关系可按能存入内存的最大尺寸读取（留足内关系缓冲区和输出空间），如内存有  $M$ 个块，每次读 $M - 2$ 个外关系块，内关系每个块与这些外关系块连接，可将内关系扫描次数从 $b_r$ 减至 $\lceil b_r / (M - 2)\rceil$ ，总块传输数为 $\lceil b_r / (M - 2)\rceil * b_s + b_r$ ，寻道数为 $2\lceil b_r / (M - 2)\rceil$ 。
        - 内循环可前后交替扫描，使磁盘块请求有序，重用缓冲区数据，减少磁盘访问。
        - 内循环连接属性有索引时，可用更高效索引查找替代文件扫描。
- **索引嵌套循环连接（Indexed Nested - Loop Join）**
    - **算法原理**：嵌套循环连接中，内循环连接属性有索引时，用索引查找替代文件扫描。对外关系 $r$ 的每个元组 $t_r$ ，用索引查找内关系 $s$ 中满足连接条件的元组。
    - **成本分析**：外关系每个元组需对 $s$ 的索引进行查找并检索相关元组。最坏情况（缓冲区只能存 $r$ 的一个块和索引的一个块）下，读关系 $r$ 需 $b_r$ 次I/O操作（每次I/O含一次寻道和一次块传输），连接成本为 $b_r(t_T + t_S) + n_r * c$ （ $n_r$ 是关系 $r$ 记录数，$c$ 是用连接条件对 $s$ 进行单次选择的成本，可参考15.3节估算）。一般有索引时，元组少的关系作外关系更高效。如 `student ⋈ takes` 示例，以 `student` 为外关系，`takes` 连接属性有聚簇B⁺树索引，总磁盘访问成本为25,100次，相比块嵌套循环连接，虽块传输减少但寻道成本增加，若 `student` 关系有大幅减少行数的选择操作，索引嵌套循环连接可能更快。
- **归并连接（Merge Join）**
    - **算法原理**：也叫排序 - 归并连接算法，用于计算自然连接和等值连接。设 $r(R)$ 和 $s(S)$ 是要计算自然连接的关系，$R ∩ S$ 是公共属性，两关系在 $R ∩ S$ 属性上排序后，连接计算过程类似归并排序的合并阶段。算法为每个关系设指针，初始指向第一个元组，过程中指针移动，将一个关系连接属性值相同的一组元组读入 $S_s$ （要求每组元组能存于主存，不满足时可用块嵌套循环连接处理），再读入另一关系对应元组并处理。
    - **成本分析**：关系排序后，连接属性值相同元组连续，每个元组和块只需读一次，对两文件各扫描一次（假设所有 $S_s$ 能存于内存），块传输数等于两关系块数之和 $b_r + b_s$ 。设为每个关系分配 $b_b$ 个缓冲区块，磁盘寻道数为 $\lceil b_r / b_b\rceil + \lceil b_s / b_b\rceil$ 。因寻道成本高，给每个关系多分配缓冲区块可减少寻道成本。若输入关系未在连接属性上排序，需先排序，再计算归并连接成本，若部分 $S_s$ 不能存于内存，成本会略有增加。如 `student ⋈ takes` 示例，连接属性为 `ID` 且关系已排序，归并连接块传输共500次，最坏情况（每个输入关系分配一个缓冲区块）寻道500次，实际可设更大 $b_b$ 减少寻道成本。   
- **混合归并连接（Hybrid Merge Join）**
    - **算法原理**：若连接属性上存在辅助索引，可对未排序元组执行归并连接变体。算法通过索引扫描记录并按序检索，但记录可能分散在文件块中，每次元组访问可能涉及磁盘块访问，成本高。为避免此成本，采用混合归并连接技术，将索引与归并连接结合。假设一个关系已排序，另一个未排序但连接属性上有辅助B⁺树索引，算法将已排序关系与辅助B⁺树索引的叶节点条目合并，结果文件包含已排序关系的元组和未排序关系元组的地址，然后按未排序关系元组地址对结果文件排序，以便按物理存储顺序高效检索相应元组完成连接。
- **哈希连接（Hash Join）**
    - **算法原理**：用于实现自然连接和等值连接。使用哈希函数 $h$ 将两个关系的元组分区，哈希函数 $h$ 将连接属性 `JoinAttrs` 的值映射到 $\{0, 1, \ldots, n_h\}$ 。关系 $r$ 的元组 $t_r$ 根据 $i = h(t_r[\text{JoinAttrs}])$ 放入分区 $r_i$ ，关系 $s$ 的元组 $t_s$ 根据 $i = h(t_s[\text{JoinAttrs}])$ 放入分区 $s_i$ 。满足连接条件的 $r$ 元组和 $s$ 元组在连接属性上哈希值相同，所以只需比较哈希值相同分区内的元组。具体过程为，先对关系 $s$ 和 $r$ 进行分区，然后为每个 $s_i$ 构建内存哈希索引，再用 $r_i$ 中的元组探测该哈希索引，找到匹配元组并连接。
    - **递归分区（Recursive Partitioning）**：若 $n_h$ 大于或等于内存块数，关系无法一次分区，需重复分区。每次将输入最多划分为与可用输出缓冲区块数相同的分区，每个分区在下一次传递时再次分区以创建更小分区，每次传递使用不同哈希函数，直到构建输入的每个分区都能存入内存，这种分区方式称为递归分区。当 $M > n_h + 1$ （约简为 
 $M > \sqrt{b_s}$ ，$M$ 为内存块数，$b_s$ 为构建关系的块数 ）时，关系无需递归分区。
    - **处理溢出（Handling of Overflows）**
        - **哈希表溢出（Hash-table overflow）**：在构建关系 $s$ 的分区 $i$ 中，若 $s_i$ 上的哈希索引大于主存，就会发生哈希表溢出。当构建关系中连接属性值相同的元组多，或哈希函数不具备随机性和均匀性时可能出现，此时分区会出现倾斜（skewed）。
        - **处理方法**：可通过增加分区数（增加一个约为哈希分区数20%的调整因子，即fudge factor ）来处理少量倾斜，使每个分区（包括分区上的哈希索引）预期大小小于内存大小。若仍发生溢出，可采用溢出解决（overflow resolution）或溢出避免（overflow avoidance）技术。溢出解决是在构建阶段检测到哈希索引溢出时，用不同哈希函数将过大的  $s_i$  进一步划分为更小分区，同时对  $r_i$  也用新哈希函数分区，只连接匹配分区内的元组；溢出避免是在构建阶段小心分区，将构建关系初始划分为许多小分区，然后合并一些分区使每个合并分区能存入内存，探测关系  $r$  按与 $s$ 合并分区相同方式分区，但  $r_i$  大小无关紧要。若 $s$ 中大量元组连接属性值相同，这两种技术可能在某些分区失效，此时可对这些分区使用其他连接技术，如块嵌套循环连接。
    - **哈希连接成本（Cost of Hash Join）**
        - **无递归分区情况**：分区需完整读取并写回两个关系，需  $2(b_r + b_s)$  次块传输（ $b_r$ 、 $b_s$ 分别是关系  $r$ 和 $s$ 的块数 ），构建和探测阶段各读一次分区，需  $b_r + b_s$  次块传输，因部分块未填满可能增加最多 $2n_h$ 次块传输开销，所以哈希连接估计需 $3(b_r + b_s) + 4n_h$ 次块传输，通常 $4n_h$ 开销相对  $b_r + b_s$ 较小可忽略。假设为输入缓冲区和每个输出缓冲区分配 $b_b$ 个块，分区需 $2(\lceil b_r / b_b\rceil + \lceil b_s / b_b\rceil)$ 次寻道，构建和探测阶段每个关系的 $n_h$ 个分区各需一次寻道，所以哈希连接需  $2(\lceil b_r / b_b\rceil + \lceil b_s / b_b\rceil) + 2n_h$  次寻道。  
- **混合哈希连接（Hybrid Hash Join）**
    - **算法原理**：当内存相对较大，但构建关系不能全部存入内存时适用。哈希连接分区阶段，每个分区需一个内存块作缓冲区，还需一个块作输入缓冲区，共需 $(n_h + 1) * b_b$ 个内存块（ $b_b$ 为输入和每个分区的缓冲区块数，$n_h$ 为分区数 ）。若内存大于 $(n_h + 1) * b_b$ ，剩余内存 $M - (n_h + 1) * b_b$  可用于缓冲构建输入的第一个分区  $s_0$  ，使  $s_0$  及其哈希索引都在内存中。分区  $r$  时，不将 $r_0$ 中元组写入磁盘，而是直接用于探测 $s_0$ 上的内存哈希索引生成连接输出元组，使用后可丢弃，节省 $r_0$ 和 $s_0$ 每个块的读写访问。其他分区正常写入磁盘，后续连接。
    - **适用条件**：若构建关系大小为 $b_s$ ，$n_h$ 约为 $b_s / M$ ，当 $M >> (b_s / M) * b_b$ （即 $M >> \sqrt{b_s * b_b}$ ，$M$ 为内存大小 ）时，混合哈希连接最有用。例如，块大小4 KB，构建关系5 GB，$b_b$ 为20，若内存显著大于20 MB，该算法有效；若分配1 GB内存用于连接算法， $s_0$  近1 GB，混合哈希连接比哈希连接成本低约20%。
- **复杂连接（Complex Joins）**
    - **处理方法**：嵌套循环连接和块嵌套循环连接可处理任意连接条件，其他连接技术（如归并连接、哈希连接）更高效，但只能处理简单连接条件（如自然连接或等值连接）。处理复杂连接条件（如合取、析取），可应用15.3.3节处理复杂选择的技术。对于合取条件连接 $r \bowtie_{\theta_1 \land \theta_2 \land \cdots \land \theta_n} s$ ，可先计算简单连接 $r \bowtie_{\theta_i} s$ ，再从中间结果中筛选满足其余条件的元组；对于析取条件连接 $r \bowtie_{\theta_1 \lor \theta_2 \lor \cdots \lor \theta_n} s$ ，可计算为各个简单连接 $r \bowtie_{\theta_i} s$ 的并集。
- **空间数据连接（Joins over Spatial Data）**
    - **挑战**：常规连接算法假设数据使用标准比较操作（如等于、小于、大于，值线性有序），但空间数据的选择和连接条件涉及区域包含、重叠或点与区域关系等比较操作，且区域可能多维，归并连接因空间数据无简单排序顺序无法使用，基于哈希的分区也不适用，嵌套循环连接对大数据集效率低。
    - **解决方案**：若有合适空间索引（如R - trees、k - d trees、k - d - B trees、quadtrees ），可使用索引嵌套循环连接。大多数主流数据库系统支持空间数据索引，处理空间比较条件查询时会利用这些索引。
### 15.6 其他操作
- **重复消除（Duplicate Elimination）**
    - **排序法**：通过排序实现，相同元组排序后相邻，可删除除一个副本外的其他副本。外部排序 - 归并时，创建运行记录时发现的重复项可在写入磁盘前删除，减少块传输，剩余重复项在合并时消除，最终排序运行记录无重复项，最坏情况成本与关系排序的最坏情况成本相同。
    - **哈希法**：基于哈希函数对整个元组分区，读取每个分区构建内存哈希索引，构建索引时只插入不存在的元组，处理完分区所有元组后，将哈希索引中的元组写入结果，成本与哈希连接中构建关系的处理成本相同。因重复消除成本相对较高，SQL需用户显式请求删除重复项，否则保留重复项。
- **投影（Projection）**
    - **实现方式**：对每个元组执行投影操作，可能产生重复记录，再用15.6.1节方法消除重复。若投影列表中的属性包含关系的键，则无重复项，无需重复消除。广义投影可按相同方式实现。
- **集合操作（Set Operations）**
    - **排序法**：实现并集、交集和差集操作，可先对两个关系排序，再扫描一次排序后的关系生成结果。对于 $r \cup s$ ，扫描时保留相同元组中的一个；$r \cap s$ 结果只包含在两个关系中都出现的元组；$r - s$ 只保留在  $r$ 中且不在 $s$ 中的元组。若关系已按相同顺序排序，成本为 $b_r + b_s$  次块传输；假设每个关系一个块缓冲区的最坏情况，除块传输外还需 $b_r + b_s$ 次磁盘寻道，分配额外缓冲区块可减少寻道次数。若关系初始未排序，需包含排序成本。
    - **哈希法**：用哈希实现，先对两个关系用相同哈希函数分区，创建分区 $r_0, r_1, \ldots, r_{n_h}$ 和 $s_0, s_1, \ldots, s_{n_h}$ 。对于 $r \cup s$ ，在 $r_i$ 上构建内存哈希索引，将 $s_i$ 中不存在的元组添加到哈希索引，再将哈希索引中的元组添加到结果。  
- **外连接（Outer Join）**
    - **实现策略**
        - **计算对应连接并添加元组**：以左外连接 $r \bowtie_{\theta} s$ 为例，先计算 $r \bowtie_{\theta} s$ 并将结果存为临时关系 $q_1$ ，再计算 $r - \Pi_R(q_1)$ 得到未参与连接的 $r$ 中元组，将这些元组对应 $s$ 属性填充空值后添加到 $q_1$ 得到左外连接结果。右外连接 $r \ltimes_{\theta} s$ 等价于 $s \bowtie_{\theta} r$ ，全外连接 $r \bowtie_{\theta} s$ 可先计算 $r \bowtie s$ ，再添加左外连接和右外连接的额外元组。
        - **修改连接算法**：嵌套循环连接算法易扩展为计算左外连接，外关系中与内关系不匹配的元组填充空值后写入输出，但难以扩展为计算全外连接。自然外连接和等值条件外连接可通过扩展归并连接和哈希连接算法计算。归并连接扩展为计算全外连接时，合并两关系中与另一关系不匹配的元组填充空值后写入输出；计算左外连接或右外连接时，只写出一个关系中不匹配的元组（填充空值）。使用归并连接算法实现外连接的成本估计与对应连接相同，差异仅在于结果大小及写出结果的块传输次数（此前成本估计未计） 。
- **聚合（Aggregation）**
    - **实现方式**：聚合操作可像重复消除一样，通过排序或哈希实现，但基于分组属性（如 `dept_name` ）。不是消除分组属性值相同的元组，而是将它们分组并对每组应用聚合操作得到结果。对于 `sum`、`min`、`max`、`count` 和 `avg` 等聚合函数，实现聚合操作的成本估计与重复消除相同。
    - **即时聚合（On - the - fly Aggregation）**：无需先收集组内所有元组再应用聚合操作，可在构建组时即时实现 `sum`、`min`、`max`、`count` 和 `avg` 聚合。对于 `sum`、`min` 和 `max` ，找到同组两个元组时，用包含聚合列 `sum`、`min` 或 `max` 的单个元组替换；对于 `count` 操作，为找到元组的每组维护运行计数；对于 `avg` 操作，即时计算 `sum` 和 `count` 值，最后相除得平均值。若结果的所有元组都能存入内存，基于排序和哈希的实现无需将元组写入磁盘，元组读入时可插入排序树结构或哈希索引。使用即时聚合技术，每组只需存储一个元组，排序树结构或哈希索引可存入内存，聚合只需 $b_r$ 次块传输（和1次寻道），而非通常的 $3b_r$ 次传输（最坏情况达 $2b_r$ 次寻道）。
### 15.7 表达式求值
- **物化（Materialization）**
    - **原理**：通过操作树直观理解表达式求值，从表达式中最低级操作（树底部）开始，使用先前学习的算法执行这些操作，结果存于临时关系，再用临时关系执行树中更高级操作，重复此过程直到计算出根操作结果。这种求值方式因创建并使用中间操作结果（物化）而称为物化求值。
    - **成本**：物化求值成本不仅是涉及操作成本之和，还需加上将操作结果写入磁盘成本。假设结果记录累积在缓冲区，满时写入磁盘，写出块数 $b_r$ 可估计为 $n_r / f_r$ （ $n_r$ 是结果关系估计元组数，$f_r$ 是结果关系块因子 ）。除传输时间外，可能需磁盘寻道，寻道数可估计为 $\lceil b_r / b_b\rceil$ （ $b_b$ 是输出缓冲区大小，以块为单位 ）。双缓冲（使用两个缓冲区，一个执行算法时另一个写入）使算法能并行执行CPU和I/O活动，加快执行速度，为输出缓冲区分配额外块并一次写出多个块可减少寻道数。
- **流水线（Pipelining）**
    - **原理**：将多个关系操作组合成操作流水线，一个操作结果传递给流水线中下一个操作，减少临时文件数量，提高查询求值效率，这种求值方式称为流水线求值。例如计算表达式 $(\Pi_{a1,a2}(r \bowtie s))$ ，物化方式需创建临时关系存储连接结果再读回执行投影，流水线方式连接操作生成结果元组时直接传递给投影操作处理，避免创建中间结果，直接生成最终结果。
    - **好处**
        - 消除读写临时关系成本，降低查询求值成本。若操作 $o_i$ 的输入来自前序操作 $o_j$ 的流水线，$o_i$ 成本不应包括从磁盘读取输入成本，此前成本公式可相应修改。
        - 若查询求值计划的根操作与输入组合在流水线中，能快速生成查询结果，对结果生成时就显示给用户的情况很有用，否则用户可能需长时间等待才能看到结果。
    - **实现方式**：可构建单个复杂操作组合构成流水线的操作来实现流水线。在图15.11示例中，选择、连接和投影三个操作可置于流水线，按生成顺序传递结果。流水线内存需求低，因操作结果不会长期存储，但操作输入不能一次全部用于处理。流水线有两种执行方式：
        - **需求驱动流水线（demand - driven pipeline）**：系统反复请求流水线顶部操作的元组，操作每次收到请求计算要返回的下一个（或一组）元组，再返回该元组。若操作输入未流水线化，从输入关系计算要返回的元组，系统跟踪已返回内容。若有流水线输入，操作也从流水线输入请求元组，用收到的元组计算输出元组并传递给父操作。
        - **生产者驱动流水线（producer - driven pipeline）**：操作不等待请求主动生成元组，每个操作建模为系统中单独进程或线程，从流水线输入获取元组流并为输出生成元组流。  
- **流水线求值算法（Evaluation Algorithms for Pipelining）**
    - **概念定义**：查询计划中标记为流水线的边称为流水线边（pipelined edges），非流水线边称为阻塞边（blocking edges）或物化边（materialized edges）。由流水线边连接的两个操作必须并发执行，因为一个操作生成元组时另一个操作消耗元组。一个计划可能有多个流水线边，由流水线边连接的所有操作必须并发执行。查询计划可划分为子树，每个子树只有流水线边，子树间的边是非流水线边，每个这样的子树称为流水线阶段（pipeline stage）。查询处理器一次执行一个流水线阶段，并在单个流水线阶段内并发执行所有操作。
    - **阻塞操作（Blocking Operations）**：有些操作如排序，本质上是阻塞操作，即需检查完所有输入元组后才能输出结果。但有趣的是，阻塞操作能在元组生成时消耗它们，并在生成时将元组输出给消费者，实际分两个或更多阶段执行，阻塞发生在阶段之间。例如外部排序 - 归并操作，有（i）运行生成和（ii）合并两个步骤。运行生成步骤可接受排序输入生成的元组，与排序输入构成流水线；合并步骤可将生成的元组发送给消费者，与消费者构成流水线，但两个步骤通过非流水线边连接，因为合并步骤要在两个输入都完成分区后才能开始。
    - **不同连接算法的流水线特性**
        - **索引嵌套循环连接**：不是本质阻塞，但特定求值算法可能阻塞。它可在外部（左）关系输出结果元组，与外部关系构成流水线；但在索引（右）输入上阻塞，因为在执行索引嵌套循环连接算法前必须先完全构建索引。
        - **哈希连接**：对两个输入都是阻塞操作，需完全检索和分区输入后才能输出元组。但哈希连接对每个输入进行分区，然后对每个分区执行多个构建 - 探测步骤，其分区步骤可与输入构成流水线，构建 - 探测步骤可与消费者构成流水线，不过两个分区步骤与构建 - 探测步骤通过非流水线边连接。
        - **混合哈希连接**：在探测关系上部分流水线化，若构建输入完全在内存中，对探测输入提供完全流水线化求值；若大部分构建输入在内存中，接近流水线化求值。
    - **双流水线连接（Double - pipelined Join）**：在更常见的输入未排序情况下，可使用双流水线连接技术。假设输入关系 $r$ 和 $s$ 的元组都流水线化，可用单个队列处理两个关系的元组，在队列中插入特殊条目 $End_r$ 和 $End_s$ 作为文件结束标记。为高效求值，应在关系 $r$ 和 $s$ 上构建合适索引，添加元组时保持索引更新。使用哈希索引时，该算法称为双流水线哈希连接技术。若输入大于内存，可用此技术直到内存满，此时将已到达的 $r$ 和 $s$ 元组分别视为分区 $r_0$ 和 $s_0$ ，后续到达的元组分别分配到 $r_1$ 和 $s_1$ 并写入磁盘，在写入磁盘前用 $r_1$ 和 $s_1$ 的元组分别探测 $s_0$ 和 $r_0$ ，处理完 $r$ 和 $s$ 后，用之前的连接技术连接 $r_1$ 和 $s_1$ 完成连接。
- **连续流数据的流水线（Pipelines for Continuous - Stream Data）**：流水线也适用于数据连续进入数据库的情况，如来自持续监测环境数据的传感器输入，这种数据称为数据流（data streams），针对此类数据的查询称为连续查询（continuous queries）。连续查询中的操作应使用流水线算法实现，以便流水线结果能无阻塞输出，生产者驱动流水线最适合连续查询求值。许多连续查询执行带窗口的聚合，翻滚窗口（tumbling windows）将时间划分为固定大小间隔（如1分钟或1小时），在每个窗口分别进行分组和聚合。若元组按时间戳有序到达，下一个窗口元组的到达表示前一个窗口不再接收元组；若元组无序到达，流必须携带标点（punctuations），表示未来所有元组时间戳大于指定值，标点到达允许输出结束时间戳小于或等于标点指定时间戳的窗口聚合结果。
### 15.8 内存中的查询处理
- **流水线实现方式**
    - **需求驱动流水线**：需求驱动流水线中的每个操作可实现为迭代器（iterator），提供 `open()`、`next()` 和 `close()` 函数。调用 `open()` 后，每次调用 `next()` 返回操作的下一个输出元组，操作实现会在需要时调用输入的 `open()` 和 `next()` 获取输入元组，`close()` 函数告知迭代器不再需要元组，迭代器在调用之间保持执行状态，以便连续的 `next()` 请求接收连续结果元组。例如，使用线性搜索实现选择操作的迭代器，`open()` 操作启动文件扫描，迭代器状态记录扫描位置，调用 `next()` 时继续扫描，找到满足选择条件的元组后返回并更新扫描位置。归并连接迭代器的 `open()` 操作打开输入，若输入未排序则排序，调用 `next()` 时返回下一对匹配元组，状态信息包含每个输入的扫描位置。
    - **生产者驱动流水线**：生产者驱动流水线中，系统为每对相邻操作创建缓冲区，用于保存从一个操作传递到下一个操作的元组，不同操作对应的进程或线程并发执行。流水线底部的操作持续生成输出元组并放入输出缓冲区，直到缓冲区满；任何其他级别的操作从流水线较低位置获取输入元组，生成输出元组放入输出缓冲区，直到缓冲区满；一旦操作使用来自流水线输入的元组，就从输入缓冲区移除该元组；输出缓冲区满时，操作等待父操作从缓冲区移除元组以腾出空间，然后继续生成元组，直到所有输出元组生成。系统仅在输出缓冲区满或输入缓冲区空且需要更多输入元组生成输出元组时，才在操作间切换。在并行处理系统中，流水线中的操作可在不同处理器上并发运行。生产者驱动流水线可看作从下往上“推送”数据，需求驱动流水线可看作从上往下“拉取”数据；生产者驱动流水线主动生成元组，需求驱动流水线按需“惰性”生成元组。需求驱动流水线更常用，因其易于实现，而生产者驱动流水线在并行处理系统中很有用。  
- **缓存感知算法（Cache-Conscious Algorithms）**
    - **内存与缓存访问速度差异**：当数据驻留在内存中时，访问速度比驻留在磁盘（甚至SSD）上快得多。而CPU缓存中的数据访问速度比内存中的数据快约100倍。现代CPU有多级缓存，常见的CPU中，L1缓存大小约64KB，延迟约1纳秒；L2缓存大小约256KB，延迟约5纳秒；L3缓存大小约10MB，延迟约10 - 15纳秒，相比之下，读取内存数据的延迟约为50 - 100纳秒。为简化，后续假设只有一级缓存。数据在主存和缓存间以缓存行（通常约64字节）为单位传输，缓存和主存的关系类似于主存和磁盘的关系（但速度差异较小），不过主存缓冲区内容由数据库系统控制，而CPU缓存由计算机硬件内置算法控制，数据库系统不能直接控制缓存内容。
    - **利用缓存优化查询处理**
        - **排序操作**：对内存中的关系排序，使用外部归并排序算法，选择合适的运行大小使其能放入缓存（以L3缓存为例，每个运行大小应为几兆字节），然后对每个运行使用内存排序算法。由于运行能放入缓存，排序时缓存未命中情况可减至最少，最后合并已排序的运行。合并操作对缓存友好，因为对运行的访问是顺序的，从内存访问特定字时，缓存行将包含该运行接下来要访问的字。对于大于内存的关系排序，可使用更大运行大小的外部归并排序，并采用上述内存排序技术对大运行进行内存排序。
        - **哈希连接操作**：哈希连接需探测构建关系上的索引。若构建关系能放入内存，可在整个关系上构建索引；为最大化探测时的缓存命中率，可将关系划分为较小部分，使构建关系的每个分区及其索引能放入缓存，分别处理每个分区（构建和探测阶段），由于构建分区及其索引在缓存中，构建和探测阶段的缓存未命中情况可减至最少。对于大于内存的关系，哈希连接的第一阶段应将两个关系分区，使每个分区对能放入内存，然后将内容读入内存，对这些分区执行哈希连接。
        - **元组属性排列**：可将元组中倾向于一起访问的属性连续存储。例如，若关系常用于聚合，可将用作分组的属性和被聚合的属性连续存储。这样，若一个属性出现缓存未命中，获取的缓存行可能包含马上要使用的其他属性。
- **查询编译（Query Compilation）**：当数据驻留在内存中时，CPU成本成为瓶颈，最小化CPU成本可带来显著好处。传统数据库查询处理器像解释器一样执行查询计划，但解释过程存在显著开销，如访问记录属性时，查询执行引擎可能反复查找关系元数据以确定属性在记录中的偏移量（因相同代码要适用于所有关系），对每个记录处理的函数调用也会产生显著开销。为避免解释开销，现代主存数据库将查询计划编译为机器码或中间级字节码。例如，编译器可在编译时计算属性偏移量并生成偏移量为常量的代码，还可合并多个函数代码以最小化函数调用。经这些及相关优化后，编译后的代码执行速度可比解释代码快10倍。
- **列存储（Column-Oriented Storage）**：在数据分析应用中，可能只需大模式中的少数属性，此时按列存储关系而非按行存储可能有优势。在列存储中对单个（或少数）属性进行选择操作成本显著更低，因为只需访问相关属性。但由于访问每个属性都需单独的数据访问，检索多个属性成本更高，若数据存储在磁盘上还可能产生额外寻道开销。列存储能一次高效访问给定属性的多个值，适合利用现代处理器的向量处理能力，使某些操作（如比较和聚合）能对多个属性值并行执行。将查询计划编译为机器码时，编译器可生成处理器支持的向量处理指令。
### 15.9 总结
- **查询处理基础流程**
    - 系统对查询的首要操作是将其转换为内部形式（关系数据库系统通常基于关系代数）。在生成查询内部形式的过程中，解析器检查用户查询语法，验证查询中出现的关系名是否为数据库中的关系名等。若查询基于视图表达，解析器用计算视图的关系代数表达式替换所有视图名引用。
    - 对于给定查询，通常有多种计算答案的方法，查询优化器负责将用户输入的查询转换为等效但能更高效计算的查询，第16章将介绍查询优化。
- **查询操作实现方式**
    - 简单选择操作可通过线性扫描或利用索引处理，复杂选择操作可通过计算简单选择结果的并集和交集来处理。
    - 对于大于内存的关系排序，可使用外部归并排序算法。
    - 涉及自然连接的查询，根据索引可用性和关系的物理存储形式，有多种处理方式：
        - 若连接结果几乎与两个关系的笛卡尔积一样大，块嵌套循环连接策略可能有优势。
        - 若有索引可用，可使用索引嵌套循环连接。
        - 若关系已排序，归并连接可能是理想选择，在连接计算前对关系排序（以便使用归并连接策略）可能有好处。
        - 哈希连接算法将关系划分为多个部分，使一个关系的每个部分能放入内存，通过对连接属性使用哈希函数进行分区，使对应的分区对能独立连接。
    - 重复消除、投影、集合操作（并集、交集和差集）以及聚合操作，可通过排序或哈希实现。
    - 外连接操作可通过对连接算法进行简单扩展来实现。
    - 哈希和排序具有对偶性，即任何可通过哈希实现的操作（如重复消除、投影、聚合、连接和外连接）也可通过排序实现，反之亦然。
- **表达式求值方式**
    - 表达式可通过物化求值，即系统计算每个子表达式结果并存储在磁盘上，然后用其计算父表达式结果。
    - 流水线求值有助于避免将许多子表达式结果写入磁盘，在子表达式结果生成时就用于父表达式计算。 
    - 为最小化内存访问成本，可使用缓存感知查询处理算法和查询编译技术，还讨论了列存储方式下的查询处理。本节介绍的算法对内存驻留数据有显著好处，对磁盘驻留数据也很有用，因为数据读入内存缓冲区后可加速处理。
>日期：5.29  

**课后习题**  
### 15.17
- **a. 计算排序成本**
    - 首先计算关系的块数 $B = \frac{40 \times 1024 \times 1024}{4} = 10485760$ 块，内存大小 $M = \frac{40 \times 1024}{4} = 10240$ 块。
    - **当 $b_b = 1$ 时**
        - 初始运行数 $n_r = \lceil\frac{B}{M}\rceil = \lceil\frac{10485760}{10240}\rceil = 1024$ 个。
        - 归并趟数 $n_p = \lceil\log_{M - 1}n_r\rceil = \lceil\log_{1023}1024\rceil = 1$ 趟。
        - 每趟的块传输数为 $2B$ （读入和写出 ），总块传输数 $T = 2B \times n_p = 2 \times 10485760 \times 1 = 20971520$ 次。
        - 寻道数 $S = B$ （每次读入一块需要一次寻道 ），寻道成本 $C_s = S \times 0.005 = 10485760 \times 0.005 = 52428.8$ 秒。
        - 传输成本 $C_t = \frac{2B}{40 \times 1024} = \frac{2 \times 10485760}{40 \times 1024} = 512$ 秒。
        - 总排序成本 $C = C_s + C_t = 52428.8 + 512 = 52940.8$ 秒。
    - **当 $b_b = 100$ 时**
        - 初始运行数 $n_r = \lceil\frac{B}{M}\rceil = 1024$ 个。
        - 归并趟数 $n_p = \lceil\log_{M - 1}n_r\rceil = 1$ 趟。
        - 每趟的块传输数为 $2B$ ，总块传输数 $T = 2B \times n_p = 20971520$ 次。
        - 寻道数 $S = \lceil\frac{B}{b_b}\rceil = \lceil\frac{10485760}{100}\rceil = 104858$ 次。
        - 寻道成本 $C_s = S \times 0.005 = 104858 \times 0.005 = 524.29$ 秒。
        - 传输成本 $C_t = \frac{2B}{40 \times 1024} = 512$ 秒。
        - 总排序成本 $C = C_s + C_t = 524.29 + 512 = 1036.29$ 秒。
- **b. 归并趟数**
    - 当 $b_b = 1$ 时，归并趟数 $n_p = \lceil\log_{M - 1}n_r\rceil = \lceil\log_{1023}1024\rceil = 1$ 趟。
    - 当 $b_b = 100$ 时，归并趟数 $n_p = \lceil\log_{M - 1}n_r\rceil = \lceil\log_{1023}1024\rceil = 1$ 趟。
- **c. 使用闪存设备时的排序成本**
    - **当 $b_b = 1$ 时**
        - 总块传输数 $T = 2B \times n_p = 20971520$ 次。
        - 寻道数 $S = B = 10485760$ 次。
        - 寻道成本 $C_s = S \times 0.00002 = 10485760 \times 0.00002 = 209.7152$ 秒。
        - 传输成本 $C_t = \frac{2B}{400 \times 1024} = \frac{2 \times 10485760}{400 \times 1024} = 51.2$ 秒。
        - 总排序成本 $C = C_s + C_t = 209.7152 + 51.2 = 260.9152$ 秒。
    - **当 $b_b = 100$ 时**
        - 总块传输数 $T = 2B \times n_p = 20971520$ 次。
        - 寻道数 $S = \lceil\frac{B}{b_b}\rceil = 104858$ 次。
        - 寻道成本 $C_s = S \times 0.00002 = 104858 \times 0.00002 = 2.09716$ 秒。
        - 传输成本 $C_t = \frac{2B}{400 \times 1024} = 51.2$ 秒。
        - 总排序成本 $C = C_s + C_t = 2.09716 + 51.2 = 53.29716$ 秒。

### 15.18
- **为什么不希望用户明确选择查询处理策略**
    - 首先，用户通常缺乏数据库内部结构、数据分布和底层算法的专业知识。让用户选择查询处理策略，他们很难做出最优决策。例如，用户可能不了解数据的索引情况、不同连接算法的适用场景等，可能会选择低效的策略，导致查询性能低下。
    - 其次，数据库系统内部的情况可能动态变化。比如数据量的增长、数据分布的改变、硬件环境的变化等，这些变化用户很难实时感知并据此调整查询策略。而数据库的查询优化器可以根据当前系统状态和数据特性自动选择最优策略。
 - **用户在哪些情况下需要了解竞争查询处理策略的成本**
    - 当用户对查询性能有严格要求，并且对数据库系统有一定了解时，他们可能需要了解查询处理策略的成本。例如，在数据仓库环境中，分析师可能需要对复杂的分析查询进行调优，此时了解不同策略的成本有助于他们与数据库管理员沟通，共同优化查询。
    - 对于一些特殊应用场景，如实时决策系统，查询的响应时间至关重要。用户（如系统开发者或管理员）需要了解不同策略的成本，以便在设计系统时选择合适的查询处理方式，满足系统的性能需求。

### 15.19
假设两个关系 $r$ 和 $s$ ，连接属性为 $A$ ，且在 $A$ 上有排序的辅助索引。以下是混合归并连接算法变体：
1. **初始化**：
    - 分别从 $r$ 和 $s$ 的辅助索引中获取指向第一个元组的指针 $p_r$ 和 $p_s$ 。
    - 初始化一个空的结果集 $result$ 。
2. **归并过程**：
    ```python
    while p_r is not None and p_s is not None:
        tuple_r = get_tuple(p_r)  # 通过指针从r中获取元组
        tuple_s = get_tuple(p_s)  # 通过指针从s中获取元组
        if tuple_r[A] < tuple_s[A]:
            p_r = get_next(p_r)  # 从r的索引中获取下一个指针
        elif tuple_r[A] > tuple_s[A]:
            p_s = get_next(p_s)  # 从s的索引中获取下一个指针
        else:
            joined_tuple = join(tuple_r, tuple_s)  # 连接两个元组
            result.append(joined_tuple)
            p_r = get_next(p_r)
            p_s = get_next(p_s)
    while p_r is not None:
        tuple_r = get_tuple(p_r)
        p_r = get_next(p_r)
    while p_s is not None:
        tuple_s = get_tuple(p_s)
        p_s = get_next(p_s)
    ```
3. **返回结果**：返回 $result$ 。

### 15.20
由于未给出Exercise 15.3中 $r_1$ 和 $r_2$ 的定义，无法准确估计块传输数和寻道数。假设 $r_1$ 有 $b_1$ 个块，$r_2$ 有 $b_2$ 个块。
 - **块传输数**：
    - 如果使用嵌套循环连接，块传输数大约为 $b_1 \times b_2$ （外循环关系 $r_1$ 每个块与内循环关系 $r_2$ 每个块进行比较 ）。
    - 如果使用归并连接，假设先对关系排序（排序成本暂不考虑 ），归并过程中块传输数大约为 $2(b_1 + b_2)$ （读入和写出 ）。
    - 如果使用哈希连接，分区和连接过程中块传输数大约为 $2(b_1 + b_2)$ （读入和写出 ）。
 - **寻道数**：
    - 嵌套循环连接中，若每次读入一块，寻道数大约为 $b_1 + b_1 \times b_2$ （外循环关系 $b_1$ 次寻道，内循环每次读入 $b_2$ 次寻道 ）。
    - 归并连接中，假设每次读入一块，寻道数大约为 $b_1 + b_2$ 。
    - 哈希连接中，假设每次读入一块，寻道数大约为 $b_1 + b_2$ 。

### 15.21
 - **自然左外连接**
    - 在哈希连接基础上，在哈希索引中为每个元组记录一个标志位，标记该元组是否已被匹配。
    - 构建阶段：对构建关系（假设为 $r$ ）进行哈希分区，将元组插入哈希索引，并将标志位初始化为未匹配（false ）。
    - 探测阶段：对探测关系（假设为 $s$ ）进行分区并探测哈希索引。当找到匹配元组时，将连接结果输出，并将哈希索引中对应元组的标志位设为已匹配（true ）。
    - 处理未匹配元组：遍历哈希索引中标志位为未匹配的元组，将其与 $s$ 中属性用空值填充后输出到结果中。
 - **自然右外连接**
    - 与自然左外连接类似，只是构建关系和探测关系互换。在哈希索引中为 $s$ 的元组记录标志位。
    - 构建阶段：对 $s$ 进行哈希分区并插入哈希索引，标志位初始化为未匹配。
    - 探测阶段：用 $r$ 探测哈希索引，匹配时输出连接结果并标记已匹配。
    - 处理未匹配元组：遍历哈希索引中未匹配的 $s$ 元组，与 $r$ 中属性用空值填充后输出到结果中。
 - **自然全外连接**
    - 分别对 $r$ 和 $s$ 进行哈希连接，得到两个部分结果。
    - 对 $r$ 执行自然左外连接，得到左外连接结果 $result_{left}$ 。
    - 对 $s$ 执行自然右外连接，得到右外连接结果 $result_{right}$ 。
    - 将 $result_{left}$ 和 $result_{right}$ 合并，去除重复元组，得到自然全外连接结果。

### 15.22
1. 首先对关系 $r$ 按属性 $A$ （如果 $A,B$ 一起则按 $A,B$ ）进行排序。
2. 初始化两个变量，分别用于存储按 $A$ 分组的 $\sum(C)$ 和按 $A,B$ 分组的 $\sum(C)$ 。
3. 遍历排序后的关系 $r$ ：
    - 维护当前分组的属性值（对于按 $A$ 分组，记录 $A$ 的值；对于按 $A,B$ 分组，记录 $A$ 和 $B$ 的值 ）。
    - 当属性值发生变化时，将当前分组的聚合结果记录下来，并重新初始化聚合值。
    - 对于每个元组，将其 $C$ 属性值累加到当前分组的聚合值中。
4. 遍历结束后，将最后一组的聚合结果记录下来。

### 15.23
```python
class SortMergeIterator:
    def __init__(self, relation1, relation2):
        self.relation1 = relation1
        self.relation2 = relation2
        self.cursor1 = iter(self.relation1)
        self.cursor2 = iter(self.relation2)
        self.current1 = next(self.cursor1, None)
        self.current2 = next(self.cursor2, None)
        self.state = {
            "last_merged": None,  # 记录上次合并的结果
            "eof1": False,  # relation1是否结束
            "eof2": False  # relation2是否结束
        }

    def open(self):
        pass

    def next(self):
        while True:
            if self.state["eof1"] and self.state["eof2"]:
                return None
            elif self.state["eof1"]:
                result = self.current2
                self.current2 = next(self.cursor2, None)
                if self.current2 is None:
                    self.state["eof2"] = True
                return result
            elif self.state["eof2"]:
                result = self.current1
                self.current1 = next(self.cursor1, None)
                if self.current1 is None:
                    self.state["eof1"] = True
                return result
            elif self.current1 < self.current2:
                result = self.current1
                self.current1 = next(self.cursor1, None)
                if self.current1 is None:
                    self.state["eof1"] = True
                return result
            elif self.current1 > self.current2:
                result = self.current2
                self.current2 = next(self.cursor2, None)
                if self.current2 is None:
                    self.state["eof2"] = True
                return result
            else:
                result = self.current1  # 这里可根据连接逻辑进行更复杂处理
                self.current1 = next(self.cursor1, None)
                self.current2 = next(self.cursor2, None)
                if self.current1 is None:
                    self.state["eof1"] = True
                if self.current2 is None:
                    self.state["eof2"] = True
                return result

    def close(self):
        pass
```

### 15.24
 - **混合哈希连接算子拆分为子算子以建模流水线**
    - **分区阶段**：将混合哈希连接的输入关系按哈希函数进行分区，这是第一个子算子。对于每个分区，将元组发送到对应的处理单元，此阶段可与输入流水线化，因为可以边接收输入边进行分区。
    - **构建 - 探测阶段**：对于每个分区，在内存中构建哈希索引（如果内存允许 ），然后进行探测操作。当构建关系的第一个分区能完全放入内存时，可立即开始输出结果，这部分可与后续操作流水线化。但如果后续分区需要等待前序分区完成构建和探测才能进行，那么分区与构建 - 探测之间存在阻塞边。
 - **与哈希连接算子拆分的不同**
    - 哈希连接算子通常分为分区和构建 - 探测两个主要阶段，且一般两个阶段之间存在阻塞边，即需要等待两个关系的所有分区都完成后才进行构建 - 探测。而混合哈希连接算子在构建关系的第一个分区能放入内存时，可提前开始输出结果，在流水线特性上更为灵活，部分操作可更早地与后续操作流水线化。

### 15.25
 - **a. 描述排序算子如何拆分为子算子以建模流水线**
    - **运行生成阶段**：将关系 $r$ 划分为多个运行（runs），每个运行可放入内存进行排序。这个阶段可以看作一个子算子，它可以与输入流水线化，即边读取 $r$ 的数据边生成运行。
    - **合并阶段**：将已排序的运行进行合并，这是第二个子算子。运行生成阶段完成一部分运行后，合并阶段可以开始处理这些运行，实现流水线操作。运行生成和合并之间的边可以是流水线边，只要内存允许，合并阶段可以在运行生成阶段生成部分运行后就开始工作。
 - **b. 内存共享对每个排序 - 归并操作成本的影响**
    - 内存共享会导致每个排序 - 归并操作可使用的内存减少。在排序 - 归并操作中，内存用于存储运行（runs）以及在合并阶段进行数据处理。内存减少会导致生成的运行数量增加，因为每个运行的大小会受限。
    - 运行数量增加会导致归并趟数可能增加。归并趟数的增加会导致块传输数和寻道数增加，从而增加排序 - 归并操作的成本
